{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rohitreddynagareddy/132test/blob/master/Cinemalytics_Chatbot_Development_Plan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_rk0_956iM6S"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Please ensure you have imported a Gemini API key from AI Studio.\n",
        "You can do this directly in the Secrets tab on the left.\n",
        "\n",
        "After doing so, please run the setup cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eYjeoOYziM6Z"
      },
      "source": [
        "!pip install -U -q \"google\"\n",
        "!pip install -U -q \"google.genai\"\n",
        "\n",
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "os.environ[\"GEMINI_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "# Please ensure that uploaded files are available in the AI Studio folder or change the working folder.\n",
        "os.chdir(\"/content/drive/MyDrive/Google AI Studio\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pejpUPLOiM6c"
      },
      "source": [
        "# Generated Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQX4NKCFiM6d"
      },
      "source": [
        "import base64\n",
        "import os\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "\n",
        "def generate():\n",
        "    client = genai.Client(\n",
        "        api_key=os.environ.get(\"GEMINI_API_KEY\"),\n",
        "    )\n",
        "\n",
        "    model = \"gemini-2.5-pro-exp-03-25\"\n",
        "    contents = [\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"As your team started to think how to build the chatbot for Cinemalytics Inc., you faced the complexities of combining Azure OpenAI and Azure AI Search. Despite the daunting task, the journey ahead appeared thrilling.\n",
        "\n",
        "You realized that you need a robust search system to efficiently retrieve information from the vast repository of movie data. The initial hurdle was to enable the chatbot to access and index the PDF documents using Azure AI Search. But first you need to upload the pdfs to the company's Blob storage.\n",
        "\n",
        "You can download a curated sample of pdfs (in a zip file) using following URL:\n",
        "\n",
        "https://openaihack.blob.core.windows.net/pdfs/pdfs.zip\n",
        "\n",
        "or\n",
        "\n",
        "https://1drv.ms/u/s!AoxLuyLmplDulZBwMEovYvPdLnM5XA?e=zIbZ1k\n",
        "\n",
        "Working closely with your team Alex formulated a plan to leverage Azure AI Search's indexing capabilities. It will map out the structure of the PDF documents, identifying key metadata such as movie titles, release dates, plot summaries, etc.\n",
        "\n",
        "With the indexing system in place, your team will move on to the second part of the challenge—integrating the chatbot with Azure OpenAI. You were provided with a GitHub repository containing a partially developed chatbot, a courtesy of one of your team members (Github repo) and you need to connect it to the deployment in Azure OpenAI service. Your team needs to study the codebase carefully, familiarize yourself with its architecture and functionality. Leverage your expertise in Python/Javascript/C# and begin the process of integration of the chatbot with Azure OpenAI's service.\n",
        "\n",
        "Once the integration is complete, your team will subjected the chatbot to testing, ensuring that it could effectively interact with Azure OpenAI and provide accurate responses to user queries. You will simulate various scenarios with different questions.\n",
        "\n",
        "In the end of the challenge, the chatbot will be fully equipped to leverage the power of Azure OpenAI and Azure AI Search, offering users a seamless and intuitive experience when exploring the vast movie database.\n",
        "\n",
        "Definition of done\n",
        "TIP: Try to do everything in Studio, using UI, before backend implementation. Make sure you're using a your private Github repo for ease of access, to commit your code frequently, preserve commit history and if needed revert back if something goes wrong.\n",
        "\n",
        "Created Azure AI Search service with index and indexer for your pdf data sitting in a blob storage\n",
        "Created Azure OpenAI resources and created a Deployment of gpt-35-turbo named turbogpt with Tokens per Rate Limit set to 40k.\n",
        "Integrated the Deployment into your chatbot programmatically\n",
        "Answered the question: \\\"List all Harry Potter movies\\\"\n",
        "Connected your data to Deployment\n",
        "Adjusted backend implementation to use your own data\n",
        "Answered following questions:\n",
        "\\\"List all Harry Potter movies\\\"\n",
        "\\\"In which movie Paul Atreides is the main character?\\\"\n",
        "Resources\n",
        ".NET\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-csharp\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/use-your-data-quickstart?tabs=bash%2Cpython-new&pivots=programming-language-csharp\n",
        "Javascript\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-javascript\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/use-your-data-quickstart?tabs=bash%2Cpython-new&pivots=programming-language-javascript\n",
        "Python\n",
        "TIP: Make sure you're using samples for right version of OpenAI Python (i.e 1.x) you installed on your machine\n",
        "\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/use-your-data-quickstart?tabs=command-line%2Cpython-new&pivots=programming-language-python\n",
        "\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"model\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Here's a breakdown of the thought process to generate the comprehensive guide for the Cinemalytics chatbot challenge:\n",
        "\n",
        "1.  **Understand the Goal:** The core objective is to build a chatbot for Cinemalytics that uses Azure OpenAI for conversational AI and Azure AI Search to retrieve information from a set of movie-related PDF documents stored in Azure Blob Storage. The chatbot should be able to answer specific questions about movies using the indexed data.\n",
        "\n",
        "2.  **Identify Key Components:**\n",
        "    *   **Data Source:** PDF documents (provided via URL).\n",
        "    *   **Data Storage:** Azure Blob Storage.\n",
        "    *   **Search/Indexing:** Azure AI Search (formerly Cognitive Search).\n",
        "    *   **Language Model:** Azure OpenAI (specifically a `gpt-35-turbo` deployment).\n",
        "    *   **Chatbot Application:** A pre-existing codebase (GitHub repo link needed, but I'll assume a standard structure for now).\n",
        "    *   **Integration:** Connecting Azure AI Search and Azure OpenAI to the chatbot application.\n",
        "    *   **Testing:** Verifying functionality with specific questions.\n",
        "\n",
        "3.  **Break Down the Task into Steps (Definition of Done):** The prompt provides a clear \\\"Definition of Done,\\\" which is perfect for structuring the solution. I'll use these as the main sections:\n",
        "    *   Upload PDFs to Blob Storage.\n",
        "    *   Create Azure AI Search service, index, and indexer.\n",
        "    *   Create Azure OpenAI resources and deploy `gpt-35-turbo`.\n",
        "    *   Integrate the *base* OpenAI deployment into the chatbot (programmatically).\n",
        "    *   Test the base integration (\\\"List all Harry Potter movies\\\" - *without* own data).\n",
        "    *   Connect the Azure AI Search data source to the Azure OpenAI deployment (\\\"Bring Your Own Data\\\").\n",
        "    *   Adjust the chatbot backend to use the data-connected deployment.\n",
        "    *   Test the data-connected integration with specific questions (\\\"List all Harry Potter movies\\\", \\\"In which movie Paul Atreides is the main character?\\\").\n",
        "\n",
        "4.  **Flesh Out Each Step - Detail the \\\"How\\\":**\n",
        "\n",
        "    *   **Step 1: Upload PDFs:**\n",
        "        *   Need an Azure Storage Account.\n",
        "        *   Need a Blob Container within it.\n",
        "        *   Download the zip file.\n",
        "        *   Unzip the file.\n",
        "        *   Use Azure Portal (Storage Explorer recommended for ease), Azure CLI, or SDKs to upload the PDFs to the container. *Mentioning multiple methods is good.*\n",
        "\n",
        "    *   **Step 2: Azure AI Search Setup:**\n",
        "        *   **Create Service:** Go to Azure Portal, search for \\\"Azure AI Search,\\\" create a new instance (choose a tier, pricing, location).\n",
        "        *   **Data Source:** Connect to the Blob Storage container created in Step 1. Needs connection string or Managed Identity.\n",
        "        *   **Skillset (Optional but Recommended for PDFs):** Mention that for PDFs, a skillset is crucial for extracting text, layout, potentially metadata. OCR skill, Text Split skill are common. *Initially, I might just mention basic indexing, but realizing PDFs need extraction, adding the skillset part is important.*\n",
        "        *   **Index:** Define the structure of the search index. What fields do we want? `content` (from PDF text), `metadata_storage_path` (useful identifier), potentially extracted fields like `title`, `release_date` if the skillset can reliably get them (though for generic PDFs, `content` is the main one). Mark fields as searchable, filterable, facetable, retrievable as needed. `content` should be searchable and retrievable.\n",
        "        *   **Indexer:** Ties the data source, skillset (if used), and index together. Set a schedule (e.g., run once, or periodically). Run the indexer to populate the index. Check indexer status and document count in the index. *Emphasize using the Azure Portal \\\"Import data\\\" wizard as it streamlines this.*\n",
        "\n",
        "    *   **Step 3: Azure OpenAI Setup:**\n",
        "        *   **Create Service:** Go to Azure Portal, search for \\\"Azure OpenAI,\\\" create a new instance (choose subscription, resource group, region, name, pricing tier). *Mention potential regional availability and quota requirements.*\n",
        "        *   **Create Deployment:** Go to Azure OpenAI Studio (linked from the resource). Navigate to \\\"Deployments.\\\" Create a new deployment. Select the `gpt-35-turbo` model. Give it the specific name `turbogpt`. Set the \\\"Tokens per Minute Rate Limit (TPM)\\\" to 40k (which translates to 40 in the portal field, as it's often in thousands). *Note this potential unit confusion.* Get the Endpoint URL and an API Key.\n",
        "\n",
        "    *   **Step 4: Integrate Base OpenAI into Chatbot:**\n",
        "        *   **Get Code:** Clone the provided GitHub repository. *Crucially state: Fork it first to your own private repo!*\n",
        "        *   **Identify Integration Point:** Look for where the chatbot code makes calls to an LLM. This might be in a specific service class, a route handler, etc. Common libraries are `openai` (Python), `@azure/openai` (JS), `Azure.AI.OpenAI` (.NET).\n",
        "        *   **Configuration:** Find where API keys and endpoints are stored (e.g., `.env` file, `appsettings.json`, environment variables). Add the Azure OpenAI Endpoint, API Key, and Deployment Name (`turbogpt`).\n",
        "        *   **Code Modification:** Update the code to use the Azure OpenAI SDK instead of potentially a generic OpenAI one, or configure the existing `openai` library for Azure. The key difference is providing the `azure_endpoint`, `api_key`, and `api_version`. Instantiate the Azure OpenAI client. Modify the function making the API call to use this client and target the `turbogpt` deployment.\n",
        "        *   **Dependencies:** Install necessary Azure OpenAI SDKs (`pip install openai`, `npm install @azure/openai`, `dotnet add package Azure.AI.OpenAI`).\n",
        "\n",
        "    *   **Step 5: Test Base Integration:**\n",
        "        *   Run the chatbot application locally.\n",
        "        *   Ask the question: \\\"List all Harry Potter movies\\\".\n",
        "        *   **Expected Outcome:** The chatbot should query the `turbogpt` deployment *without* using the indexed data. The answer will come from the model's general knowledge, which should be pretty good for Harry Potter. The purpose here is just to verify the *connection* to Azure OpenAI works.\n",
        "\n",
        "    *   **Step 6: Connect Data (Bring Your Own Data - BYOD):**\n",
        "        *   **Method:** The easiest way is using Azure OpenAI Studio.\n",
        "        *   **Steps in Studio:**\n",
        "            *   Go to the \\\"Chat playground\\\".\n",
        "            *   Select the `turbogpt` deployment.\n",
        "            *   Click \\\"Add your data\\\".\n",
        "            *   Choose \\\"Azure AI Search\\\" as the data source.\n",
        "            *   Select the Azure AI Search service created in Step 2.\n",
        "            *   Select the index created in Step 2.\n",
        "            *   Map index fields: `content` field to \\\"Content data\\\", `metadata_storage_path` (or similar) to \\\"Filepath\\\". Choose a \\\"Title field\\\" if available, otherwise use filepath.\n",
        "            *   Configure search options (semantic search - recommended if tier supports it, query type, strictness, document count).\n",
        "            *   Save the configuration.\n",
        "        *   **Deployment Update:** After adding the data source in the playground, *Deploy* this configuration. Choose \\\"Deploy to a new web app\\\" or \\\"Deploy to an existing web app.\\\" More importantly for *programmatic* use, note the updated configuration details shown in the studio (specifically how the data source is referenced). The *key point* is that the *same deployment name* (`turbogpt`) now has this data source linked *within the Azure OpenAI service itself*.\n",
        "\n",
        "    *   **Step 7: Adjust Backend for BYOD:**\n",
        "        *   **Key Change:** When calling the Azure OpenAI Completions API (`chat.completions.create`), you now need to include the `data_sources` parameter (or `dataSource` in some SDK versions/styles) pointing to the Azure AI Search configuration.\n",
        "        *   **How to get the `data_sources` info:** The Azure OpenAI Studio's \\\"View code\\\" feature after adding data is the best way. It shows the exact JSON structure needed for the `data_sources` parameter, including the search service endpoint, key (or Managed Identity), index name, and field mappings.\n",
        "        *   **Code Modification:** Update the API call in the chatbot backend code to include this `data_sources` section. Ensure the SDK version supports this (OpenAI Python >= 1.0 often requires it structured within `extra_body` or specific arguments depending on the exact version and how Azure compatibility is handled). *Check the provided Microsoft Learn links for the specific SDK syntax.*\n",
        "        *   **Configuration:** You might need to add the AI Search endpoint and API key (or configure Managed Identity) to your chatbot's configuration as well, as these are often needed in the `data_sources` payload.\n",
        "\n",
        "    *   **Step 8: Test Data-Connected Integration:**\n",
        "        *   Restart the chatbot application.\n",
        "        *   Ask: \\\"List all Harry Potter movies\\\".\n",
        "            *   **Expected Outcome:** The response should now potentially include citations or explicitly mention it's using the provided documents. The list should ideally come *from the PDFs*. If the PDFs only contain info on *some* HP movies, the answer should reflect that.\n",
        "        *   Ask: \\\"In which movie Paul Atreides is the main character?\\\"\n",
        "            *   **Expected Outcome:** Assuming one of the PDFs is about \\\"Dune,\\\" the chatbot should correctly identify \\\"Dune\\\" (or the specific movie title if the PDF mentions it) and potentially provide context from that PDF, along with citations. If no PDF mentions Dune/Paul Atreides, it should state it couldn't find the information in the provided documents.\n",
        "\n",
        "5.  **Add Important Considerations:**\n",
        "    *   **Security:** Use Managed Identities instead of keys where possible. Store keys securely (Key Vault).\n",
        "    *   **Error Handling:** Implement robust error handling for API calls, indexing issues, etc.\n",
        "    *   **Cost:** Be mindful of Azure service costs (Storage, AI Search Tiers, OpenAI tokens).\n",
        "    *   **Versioning:** Use Git correctly (forking, committing).\n",
        "    *   **Tooling:** Mention Azure Portal, Azure OpenAI Studio, Azure Storage Explorer, VS Code (or preferred IDE).\n",
        "    *   **Language Choice:** Acknowledge the prompt allows C#, JS, Python and tailor code snippets/library names accordingly (though the provided links handle this).\n",
        "    *   **PDF Quality:** Note that the quality/structure of the PDFs heavily influences search results. Skillsets help, but aren't magic.\n",
        "\n",
        "6.  **Structure and Formatting:** Organize the steps logically with clear headings. Use code blocks for commands and snippets. Use bold text for emphasis. Add tips and warnings. Start with an introduction summarizing the task and end with a concluding remark.\n",
        "\n",
        "7.  **Review and Refine:** Read through the entire guide. Does it flow logically? Is it clear? Are there any ambiguities? Is the level of detail appropriate? Did I address all parts of the prompt and the Definition of Done? *Self-correction: Initially, I might have forgotten to emphasize forking the repo or checking the exact SDK syntax for BYOD, so add those in.* Ensure the Azure resource names (`turbogpt`) match the prompt. Make sure the testing steps clearly differentiate between base OpenAI and data-connected OpenAI.\"\"\"),\n",
        "                types.Part.from_text(text=\"\"\"Okay, let's embark on this exciting journey to build the Cinemalytics chatbot! This is a common and powerful pattern: using a search index for retrieval combined with a large language model for generation and understanding (Retrieval-Augmented Generation - RAG).\n",
        "\n",
        "Here’s a step-by-step guide following the plan and Definition of Done:\n",
        "\n",
        "**Phase 1: Data Preparation and Indexing**\n",
        "\n",
        "1.  **Download and Prepare PDFs:**\n",
        "    *   Download the `pdfs.zip` file from either URL:\n",
        "        *   [https://openaihack.blob.core.windows.net/pdfs/pdfs.zip](https://openaihack.blob.core.windows.net/pdfs/pdfs.zip)\n",
        "        *   [https://1drv.ms/u/s!AoxLuyLmplDulZBwMEovYvPdLnM5XA?e=zIbZ1k](https://1drv.ms/u/s!AoxLuyLmplDulZBwMEovYvPdLnM5XA?e=zIbZ1k)\n",
        "    *   Unzip the file to a local folder. You should see several PDF files related to movies.\n",
        "\n",
        "2.  **Create Azure Storage Account and Upload PDFs:**\n",
        "    *   Log in to the Azure Portal ([https://portal.azure.com](https://portal.azure.com)).\n",
        "    *   Create a new **Storage Account**.\n",
        "        *   Choose a Subscription and Resource Group (create a new one if needed, e.g., `rg-cinemalytics`).\n",
        "        *   Give it a unique name (e.g., `stcinemalyticsdata` followed by unique characters).\n",
        "        *   Choose a Region.\n",
        "        *   Select performance/redundancy (Standard/GRS is usually fine for this).\n",
        "        *   Review and create.\n",
        "    *   Once deployed, navigate to the Storage Account.\n",
        "    *   Go to **Containers** under \\\"Data storage\\\".\n",
        "    *   Create a new container named `pdfs`. Set the public access level to `Private`.\n",
        "    *   Navigate into the `pdfs` container.\n",
        "    *   Click **Upload**. Select all the PDF files you unzipped earlier and upload them.\n",
        "\n",
        "3.  **Create Azure AI Search Service:**\n",
        "    *   In the Azure Portal, search for and create a new **Azure AI Search** service.\n",
        "        *   Choose the same Subscription and Resource Group.\n",
        "        *   Give it a unique name (e.g., `search-cinemalytics`).\n",
        "        *   Choose the same Region as your storage account if possible.\n",
        "        *   Select a Pricing Tier. The **Basic** tier is usually sufficient to start and supports Semantic Search (highly recommended for RAG). The **Free** tier is limited.\n",
        "        *   Review and create.\n",
        "\n",
        "4.  **Create Index and Indexer using \\\"Import data\\\" Wizard:**\n",
        "    *   Navigate to your newly created Azure AI Search service.\n",
        "    *   Click on **Import data**.\n",
        "    *   **Connect to your data:**\n",
        "        *   **Data Source:** Choose `Azure Blob Storage`.\n",
        "        *   **Data source name:** `cinemalytics-blob-datasource`.\n",
        "        *   **Data to extract:** `Content and Metadata`.\n",
        "        *   **Parsing mode:** `Default`.\n",
        "        *   **Connection string:** Click `Choose an existing connection`, select your storage account, then select the `pdfs` container. Authentication via Account Key is simplest for this exercise, but Managed Identity is better practice for production.\n",
        "        *   Leave other settings as default and click **Next: Add cognitive skills (Optional)**.\n",
        "    *   **Add cognitive skills (Optional but Recommended for PDFs):**\n",
        "        *   Expand **Attach Cognitive Services**. You can use the Free one for limited testing or create a new Azure AI Services multi-service account. *This step is needed for skills like OCR.*\n",
        "        *   Enable **OCR** to extract text from images within PDFs (if any).\n",
        "        *   Enable **Extract document structure** -> `Merge all text into 'merged_content' field`. This is often simpler than relying on complex chunking here, as the OpenAI integration can handle chunking/summarization later. *Alternatively, use the `Split text` skill for more granular chunks if preferred.* Let's proceed with `merged_content` for now.\n",
        "        *   *Optional:* Add other skills like Entity Recognition (Organizations, Persons, Locations), Key Phrase Extraction if desired, but keep it simple initially. `merged_content` is key.\n",
        "        *   Click **Next: Customize target index**.\n",
        "    *   **Customize target index:**\n",
        "        *   **Index name:** `cinemalytics-index`.\n",
        "        *   **Key:** Ensure `metadata_storage_path` is selected (or let it generate one). Make it `Retrievable`.\n",
        "        *   **Fields:** Review the fields. The wizard likely added `merged_content` (from the skillset), `metadata_storage_name`, `metadata_storage_path`, etc.\n",
        "            *   Ensure `merged_content` is `Retrievable` and `Searchable`. Choose an appropriate analyzer (e.g., `English - Microsoft`).\n",
        "            *   Make `metadata_storage_name` `Retrievable`, `Filterable`, `Sortable`, `Facetable`.\n",
        "            *   Mark `metadata_storage_path` as `Retrievable`.\n",
        "        *   **Semantic Search:** If you chose a tier that supports it (like Basic or higher), enable Semantic Search. Choose a Semantic configuration (create a new one if needed). Select `merged_content` as the \\\"Title Field\\\" (or `metadata_storage_name`) and \\\"Content Fields\\\". This significantly improves search relevance for natural language queries.\n",
        "        *   Click **Next: Create an indexer**.\n",
        "    *   **Create an indexer:**\n",
        "        *   **Name:** `cinemalytics-indexer`.\n",
        "        *   **Schedule:** `Once`.\n",
        "        *   Leave other options default. Click **Submit**.\n",
        "    *   **Monitor Indexing:** Go to the **Indexers** tab in your AI Search service. Select `cinemalytics-indexer`. It should start running. Wait for it to complete successfully (it should show the number of documents indexed, matching the number of PDFs uploaded). You can check the **Indexes** tab and `cinemalytics-index` to see the document count.\n",
        "\n",
        "    *   **DONE: Created Azure AI Search service with index and indexer for your pdf data sitting in a blob storage**\n",
        "\n",
        "**Phase 2: Azure OpenAI Setup and Basic Integration**\n",
        "\n",
        "5.  **Create Azure OpenAI Resource and Deployment:**\n",
        "    *   In the Azure Portal, search for and create a new **Azure OpenAI** service.\n",
        "        *   Choose Subscription and Resource Group.\n",
        "        *   Choose a Region where `gpt-3.5-turbo` is available.\n",
        "        *   Give it a unique name (e.g., `openai-cinemalytics`).\n",
        "        *   Choose the `Standard S0` pricing tier.\n",
        "        *   Review network settings, tags, etc. Review and Create. *Note: You might need to apply for access to Azure OpenAI depending on your subscription.*\n",
        "    *   Once deployed, navigate to the resource.\n",
        "    *   Go to **Model deployments** under \\\"Resource Management\\\". Click **Manage Deployments** - this opens the **Azure OpenAI Studio**.\n",
        "    *   Click **+ Create new deployment**.\n",
        "        *   **Model:** Select `gpt-35-turbo`. *Ensure you choose a version compatible with the SDK/API calls you intend to make (e.g., 0613 or later usually works well).*\n",
        "        *   **Deployment name:** `turbogpt` (exactly as specified).\n",
        "        *   **Advanced options:** Set **Tokens per Minute Rate Limit (TPM)** to `40` (this usually means 40,000 TPM).\n",
        "        *   Click **Create**.\n",
        "    *   **Get Credentials:** While in the Azure OpenAI Studio or the Azure Portal resource page (under **Keys and Endpoint**), note down:\n",
        "        *   Your Azure OpenAI **Endpoint** URL.\n",
        "        *   One of the **API Keys**.\n",
        "\n",
        "    *   **DONE: Created Azure OpenAI resources and created a Deployment of gpt-35-turbo named turbogpt with Tokens per Rate Limit set to 40k.**\n",
        "\n",
        "6.  **Integrate Base Deployment into Chatbot:**\n",
        "    *   **Fork and Clone Repo:** Go to the provided GitHub repository URL. **Fork** it into your own GitHub account (this creates your private copy). Clone *your forked repository* to your local machine.\n",
        "    *   **Set up Environment:** Follow the `README.md` in the repository to set up the project (e.g., install dependencies `pip install -r requirements.txt`, `npm install`, or `dotnet restore`).\n",
        "    *   **Configure Credentials:** Find the configuration file (e.g., `.env`, `appsettings.json`, `config.py`) in the cloned repository. Update it with:\n",
        "        *   `AZURE_OPENAI_ENDPOINT`: Your Azure OpenAI Endpoint URL.\n",
        "        *   `AZURE_OPENAI_API_KEY`: Your Azure OpenAI API Key.\n",
        "        *   `AZURE_OPENAI_DEPLOYMENT_NAME`: `turbogpt`\n",
        "        *   `AZURE_OPENAI_API_VERSION`: A recent API version (check Azure documentation or SDK examples, e.g., `2023-07-01-preview` or `2024-02-15-preview`).\n",
        "    *   **Update Code (Example - Python using `openai` >= 1.0):** Find the part of the code making the OpenAI call. Modify it to use the Azure credentials.\n",
        "\n",
        "        ```python\n",
        "        import os\n",
        "        from openai import AzureOpenAI\n",
        "        from dotenv import load_dotenv\n",
        "\n",
        "        load_dotenv() # Load environment variables from .env file\n",
        "\n",
        "        # Check if Azure environment variables are set\n",
        "        use_azure = all([\n",
        "            os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\n",
        "            os.getenv(\\\"AZURE_OPENAI_API_KEY\\\"),\n",
        "            os.getenv(\\\"AZURE_OPENAI_DEPLOYMENT_NAME\\\"),\n",
        "            os.getenv(\\\"AZURE_OPENAI_API_VERSION\\\")\n",
        "        ])\n",
        "\n",
        "        if use_azure:\n",
        "            print(\\\"Using Azure OpenAI configuration.\\\")\n",
        "            client = AzureOpenAI(\n",
        "                azure_endpoint=os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\"),\n",
        "                api_key=os.getenv(\\\"AZURE_OPENAI_API_KEY\\\"),\n",
        "                api_version=os.getenv(\\\"AZURE_OPENAI_API_VERSION\\\"),\n",
        "            )\n",
        "            deployment_name = os.getenv(\\\"AZURE_OPENAI_DEPLOYMENT_NAME\\\")\n",
        "        else:\n",
        "            # Fallback or error handling if needed\n",
        "            print(\\\"Azure OpenAI environment variables not fully set.\\\")\n",
        "            # Example: client = OpenAI(api_key=os.getenv(\\\"OPENAI_API_KEY\\\"))\n",
        "            # For this task, we assume Azure is required.\n",
        "            raise ValueError(\\\"Azure OpenAI configuration is required for this application.\\\")\n",
        "\n",
        "        # --- Example function making the call ---\n",
        "        def ask_openai_basic(question):\n",
        "            try:\n",
        "                response = client.chat.completions.create(\n",
        "                    model=deployment_name, # Use the deployment name for Azure\n",
        "                    messages=[\n",
        "                        {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a helpful assistant.\\\"},\n",
        "                        {\\\"role\\\": \\\"user\\\", \\\"content\\\": question}\n",
        "                    ],\n",
        "                    temperature=0.7,\n",
        "                    max_tokens=800\n",
        "                )\n",
        "                return response.choices[0].message.content\n",
        "            except Exception as e:\n",
        "                print(f\\\"An error occurred: {e}\\\")\n",
        "                return \\\"Sorry, I encountered an error.\\\"\n",
        "\n",
        "        # --- Test the basic integration ---\n",
        "        if __name__ == \\\"__main__\\\":\n",
        "             # This is just for direct script testing; adapt to your chatbot's entry point\n",
        "             test_question = \\\"List all Harry Potter movies\\\"\n",
        "             print(f\\\"Q: {test_question}\\\")\n",
        "             answer = ask_openai_basic(test_question)\n",
        "             print(f\\\"A: {answer}\\\")\n",
        "\n",
        "        ```\n",
        "        *Adapt this logic to fit the specific structure of the provided chatbot codebase (e.g., inside a class, within API route handlers).*\n",
        "        *Ensure you have the correct package installed: `pip install openai>=1.0.0 python-dotenv`*\n",
        "\n",
        "    *   **DONE: Integrated the Deployment into your chatbot programmatically**\n",
        "\n",
        "7.  **Test Basic Integration:**\n",
        "    *   Run your chatbot application locally.\n",
        "    *   Interact with the chatbot interface (or use the test script if applicable).\n",
        "    *   Ask the question: `\\\"List all Harry Potter movies\\\"`\n",
        "    *   **Verify:** The chatbot should respond using the general knowledge of the `gpt-35-turbo` model. It hasn't used your PDF data yet. The answer should be a standard list of the 8 main HP movies.\n",
        "\n",
        "    *   **DONE: Answered the question: \\\"List all Harry Potter movies\\\" (using base model)**\n",
        "\n",
        "**Phase 3: Connecting Data and Final Testing**\n",
        "\n",
        "8.  **Connect Your Data (Azure AI Search) to the Deployment:**\n",
        "    *   Go back to the **Azure OpenAI Studio**.\n",
        "    *   Select the **Chat** playground from the left menu.\n",
        "    *   Under **Configuration** -> **Deployment**, make sure your `turbogpt` deployment is selected.\n",
        "    *   Click on the **+ Add your data** tab (next to \\\"Setup\\\").\n",
        "    *   Click **+ Add a data source**.\n",
        "    *   Select **Azure AI Search**.\n",
        "    *   Choose your Azure AI Search service (`search-cinemalytics`).\n",
        "    *   Choose your index (`cinemalytics-index`).\n",
        "    *   **Index field mapping:**\n",
        "        *   **Content data:** Select `merged_content`.\n",
        "        *   **Filepath field:** Select `metadata_storage_path`.\n",
        "        *   **Title field:** Select `metadata_storage_name`.\n",
        "        *   **URL field:** (Optional) Leave blank or use `metadata_storage_path` if relevant.\n",
        "        *   **Vector fields:** (Optional) Leave blank unless you specifically added vector embeddings during indexing.\n",
        "    *   **Search options:**\n",
        "        *   Enable **Semantic search** if you enabled it on your index (recommended). Use the existing semantic configuration.\n",
        "        *   **Query type:** `Vector + Semantic` or `Semantic` (if no vectors). Start with `Semantic`.\n",
        "    *   Acknowledge the usage costs.\n",
        "    *   Click **Next** and then **Save and close**.\n",
        "    *   Your `turbogpt` deployment in the chat playground is now configured to use your AI Search index. *Crucially, this connection exists within the Azure OpenAI service infrastructure when accessed via specific API parameters.*\n",
        "\n",
        "    *   **DONE: Connected your data to Deployment**\n",
        "\n",
        "9.  **Adjust Backend Implementation to Use Your Own Data:**\n",
        "    *   **Get Data Source Configuration:** In the Azure OpenAI Studio Chat playground, with your data source added, look for the \\\"View code\\\" button. Click it. It will show sample code. The important part is the `data_sources` (or sometimes `dataSources` or within `extra_body` depending on SDK/version) parameter being passed to the `client.chat.completions.create` method. Copy this JSON structure.\n",
        "    *   **Update Code (Example - Python using `openai` >= 1.0):** Modify the function making the API call to include the `data_sources` parameter within `extra_body`.\n",
        "\n",
        "        ```python\n",
        "        import os\n",
        "        from openai import AzureOpenAI\n",
        "        from dotenv import load_dotenv\n",
        "\n",
        "        load_dotenv()\n",
        "\n",
        "        # --- Assume client and deployment_name are set up as before ---\n",
        "        client = AzureOpenAI(...)\n",
        "        deployment_name = os.getenv(\\\"AZURE_OPENAI_DEPLOYMENT_NAME\\\")\n",
        "\n",
        "        # --- Add configuration for Azure AI Search ---\n",
        "        # Store these securely, e.g., in .env or Key Vault\n",
        "        search_endpoint = os.getenv(\\\"AZURE_AI_SEARCH_ENDPOINT\\\") # e.g., https://search-cinemalytics.search.windows.net\n",
        "        search_key = os.getenv(\\\"AZURE_AI_SEARCH_API_KEY\\\")       # An admin or query key for your search service\n",
        "        search_index_name = \\\"cinemalytics-index\\\"\n",
        "\n",
        "        # --- Function to ask using own data ---\n",
        "        def ask_openai_with_data(question):\n",
        "            try:\n",
        "                # Construct the data_sources payload\n",
        "                # This structure might vary slightly based on exact API version and SDK handling\n",
        "                # Refer to \\\"View code\\\" in Azure OpenAI Studio for the most accurate structure\n",
        "                data_sources_payload = [\n",
        "                    {\n",
        "                        \\\"type\\\": \\\"azure_search\\\",\n",
        "                        \\\"parameters\\\": {\n",
        "                            \\\"endpoint\\\": search_endpoint,\n",
        "                            \\\"index_name\\\": search_index_name,\n",
        "                            \\\"authentication\\\": {\n",
        "                                \\\"type\\\": \\\"api_key\\\",\n",
        "                                \\\"key\\\": search_key\n",
        "                            },\n",
        "                            # Optional: Configure field mapping, query type, semantic config etc.\n",
        "                            # if different from Studio default or needs runtime change\n",
        "                            \\\"semantic_configuration\\\": \\\"default\\\", # Use the name of your semantic config\n",
        "                            \\\"query_type\\\": \\\"semantic\\\",\n",
        "                            \\\"fields_mapping\\\": {\n",
        "                                \\\"content_fields\\\": [\\\"merged_content\\\"],\n",
        "                                \\\"title_field\\\": \\\"metadata_storage_name\\\",\n",
        "                                \\\"filepath_field\\\": \\\"metadata_storage_path\\\"\n",
        "                            },\n",
        "                            \\\"in_scope\\\": True, # Use this data source for the query\n",
        "                            \\\"strictness\\\": 3,  # Adjust strictness (1-5)\n",
        "                            \\\"top_n_documents\\\": 5 # Number of docs to retrieve\n",
        "                        }\n",
        "                    }\n",
        "                ]\n",
        "\n",
        "                # Make the API call including data_sources via extra_body\n",
        "                response = client.chat.completions.create(\n",
        "                    model=deployment_name,\n",
        "                    messages=[\n",
        "                        {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are an AI assistant helping with movie information based on provided documents. Be concise and cite your sources.\\\"},\n",
        "                        {\\\"role\\\": \\\"user\\\", \\\"content\\\": question}\n",
        "                    ],\n",
        "                    temperature=0.7,\n",
        "                    max_tokens=800,\n",
        "                    # Pass data_sources configuration\n",
        "                    extra_body={\n",
        "                        \\\"data_sources\\\": data_sources_payload\n",
        "                    }\n",
        "                )\n",
        "\n",
        "                # The response structure might include citations if data was used\n",
        "                # Check response.choices[0].message.context or similar depending on API version\n",
        "                # For now, just return the main content\n",
        "                return response.choices[0].message.content\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\\\"An error occurred: {e}\\\")\n",
        "                return \\\"Sorry, I encountered an error processing your request with data.\\\"\n",
        "\n",
        "        # --- Test the data-connected integration ---\n",
        "        if __name__ == \\\"__main__\\\":\n",
        "             # Add Search Endpoint/Key to your .env or environment variables\n",
        "             # AZURE_AI_SEARCH_ENDPOINT=https://your-search-service-name.search.windows.net\n",
        "             # AZURE_AI_SEARCH_API_KEY=YourSearchServiceQueryOrAdminKey\n",
        "\n",
        "             # Reload env if needed or ensure they are set\n",
        "             load_dotenv()\n",
        "             search_endpoint = os.getenv(\\\"AZURE_AI_SEARCH_ENDPOINT\\\")\n",
        "             search_key = os.getenv(\\\"AZURE_AI_SEARCH_API_KEY\\\")\n",
        "             if not all([search_endpoint, search_key]):\n",
        "                 raise ValueError(\\\"Azure AI Search endpoint and key must be configured.\\\")\n",
        "\n",
        "             questions = [\n",
        "                 \\\"List all Harry Potter movies\\\",\n",
        "                 \\\"In which movie Paul Atreides is the main character?\\\"\n",
        "             ]\n",
        "             for q in questions:\n",
        "                 print(f\\\"\\\\nQ: {q}\\\")\n",
        "                 answer = ask_openai_with_data(q)\n",
        "                 print(f\\\"A: {answer}\\\")\n",
        "\n",
        "        ```\n",
        "        *   **Important:**\n",
        "            *   Add `AZURE_AI_SEARCH_ENDPOINT` and `AZURE_AI_SEARCH_API_KEY` to your configuration (`.env`, etc.). Get the Search Endpoint from the Overview page of your AI Search service and an API Key from the \\\"Keys\\\" section (a Query Key is sufficient and safer than an Admin Key).\n",
        "            *   Make sure the `fields_mapping`, `semantic_configuration`, and `query_type` in the code match how you configured it in the Azure OpenAI Studio and your AI Search index.\n",
        "            *   The exact way to pass `data_sources` (`extra_body` vs. direct parameter) depends *heavily* on the specific `openai` Python SDK version and how Azure compatibility is implemented. Check the official Azure OpenAI Python SDK documentation for your version. The `extra_body` approach is common for newer versions when features aren't yet first-class parameters.\n",
        "\n",
        "    *   **DONE: Adjusted backend implementation to use your own data**\n",
        "\n",
        "10. **Final Testing:**\n",
        "    *   Restart your chatbot application.\n",
        "    *   Ask the questions again:\n",
        "        *   `\\\"List all Harry Potter movies\\\"`\n",
        "            *   **Expected:** The answer should now be based *only* on the information present in your indexed PDFs. If the PDFs only mention a few HP movies, the list should reflect that. The response might include citations referencing the specific PDFs (e.g., `[doc1]`). If the PDFs don't mention Harry Potter *at all*, the chatbot should indicate it couldn't find the information in the provided documents.\n",
        "        *   `\\\"In which movie Paul Atreides is the main character?\\\"`\n",
        "            *   **Expected:** Assuming one of the PDFs discusses the movie \\\"Dune\\\", the chatbot should identify \\\"Dune\\\" and likely provide context pulled directly from that PDF, potentially citing the document. If no PDF covers Dune, it should state that the information isn't available in the provided data.\n",
        "\n",
        "    *   **DONE: Answered following questions (using own data):**\n",
        "        *   **\\\"List all Harry Potter movies\\\"**\n",
        "        *   **\\\"In which movie Paul Atreides is the main character?\\\"**\n",
        "\n",
        "**Conclusion**\n",
        "\n",
        "You have now successfully built a chatbot prototype for Cinemalytics! It leverages Azure Blob Storage for data persistence, Azure AI Search for efficient information retrieval from PDF documents, and Azure OpenAI's `gpt-35-turbo` model (connected to your data) for natural language understanding and response generation. Remember to commit your code changes frequently to your private GitHub repository. This setup provides a powerful foundation for answering user queries based on your company's specific knowledge base.\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Challenge 2: Paint me a picture\n",
        "Scenario overview\n",
        "Your management was delighted with the chatbot you created in a previous challenge and were assured that you can tackle anything they throw at you. Your team were given a new task. Management wants you to make it more personalized in order to gather more data on their users.\n",
        "\n",
        "Your team explored different image generators but in the end you've decided to proceed with Dall-E image generator. This will be a unique opportunity to leverage an image generator to create personalized avatars for your chatbot. This task added an exciting dimension to your project, requiring you to craft detailed prompt and integrate the generated avatars seamlessly into the chatbot interface.\n",
        "\n",
        "The challenge began with the team brainstorming the specific features and characteristics that users might want to include in their avatars. Drawing inspiration from the provided inputs from the management, they identified key elements such as facial features, hairstyle, clothing preferences, and stylistic preferences.\n",
        "\n",
        "To streamline the avatar creation process, the team devised a simple form that users could fill out to specify their preferences. The form included fields for selecting gender, ethnicity, facial shape, eye color, beard and mustache style, hair color and length, as well as any additional accessories or clothing preferences. Each field was designed to capture the user's unique vision for their avatar, ensuring a personalized and immersive experience.\n",
        "\n",
        "As they implemented the form, the team carefully extracted specific features that will create the prompt, such as facial symmetry, oval face shape, thin eyebrows, brown eyes, full beard and mustache, short brown hair, and the preferred Pixar-like 3D style. These features were incorporated into the form, allowing users to customize their avatars according to their preferences.\n",
        "\n",
        "Your marketing team provided you with prompt that needs to implemented:\n",
        "\n",
        "\\\"Create me a portrait of 3d Pixar-like style character that will be my avatar. I am caucausian male, have simmetric, oval face with medium thin eyebrows, brown eyes, 4mm full beard and moustache, short brown hair. Avatar is wearing official Manchester United jersey and red baseball cap.\\\"\n",
        "\n",
        "Once the form was finalized, the team focused on integrating the DALL-E image generator into the chatbot interface. They developed functionality that would generate a prompt based on the user's input, dynamically adjusting the request to reflect the selected features and preferences. The generated prompt would then be sent to the DALL-E API, which would produce a custom avatar based on the user's specifications.\n",
        "\n",
        "To complete the integration, the team programmed the chatbot to insert the generated avatar seamlessly into the conversation interface. Users could view their avatars in real-time as they interacted with the chatbot, enhancing their engagement and immersion in the experience.\n",
        "\n",
        "With the avatar creation feature successfully implemented, your development team at Cinemalytics Inc. will achieve a significant milestone in the project. Your innovative approach will transform the chatbot into a dynamic and personalized platform, empowering users to express their individuality and creativity in exciting new ways.\n",
        "\n",
        "Definition of Done\n",
        "TIP: Try to do everything in Studio through UI before backend implementation\n",
        "\n",
        "New chat-gpt model is created (or the old one is used) that will act as a prompt generator using the avatar features from the chatbot form\n",
        "Dall-E model deployed in Azure OpenAI instance\n",
        "Backend implementation is needed and data from input form on chatbot UI will be used to generate the prompt. Generated prompt will then be sent to the Dall-E image generator.\n",
        "Integrated response into chatbot as an avatar to personalize application\n",
        "Resources\n",
        ".NET\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/dall-e-quickstart?tabs=dalle3%2Ccommand-line&pivots=programming-language-csharp\n",
        "\n",
        "Javascript\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/dall-e-quickstart?tabs=dalle3%2Ccommand-line&pivots=programming-language-javascript\n",
        "\n",
        "Python\n",
        "https://learn.microsoft.com/en-us/azure/ai-services/openai/dall-e-quickstart?tabs=dalle3%2Ccommand-line&pivots=programming-language-python\n",
        "\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"model\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Here's a breakdown of the thought process to generate the solution for Challenge 2:\n",
        "\n",
        "1.  **Understand the Goal:** The core requirement is to add a personalized avatar generation feature to the existing chatbot. This involves:\n",
        "    *   Collecting user preferences via a form.\n",
        "    *   Using these preferences to generate a *detailed prompt* suitable for an image generator.\n",
        "    *   Using Azure OpenAI's DALL-E model to generate an image based on that prompt.\n",
        "    *   Displaying the generated image (avatar) back to the user within the chatbot interface.\n",
        "\n",
        "2.  **Identify Key Components & Technologies:**\n",
        "    *   **User Interface (UI):** A form within the chatbot to collect avatar preferences (gender, ethnicity, facial features, hair, clothing, style). The existing chatbot codebase needs modification.\n",
        "    *   **Prompt Generation:** This is a crucial step. Taking structured form data (e.g., `gender: male`, `ethnicity: caucasian`, `hair_length: short`) and turning it into a descriptive natural language prompt like the example given. An LLM (like GPT-3.5/4) is ideal for this transformation.\n",
        "    *   **Image Generation:** Azure OpenAI DALL-E (specifically DALL-E 3, as it's better with detailed prompts). Requires deployment within the Azure OpenAI service.\n",
        "    *   **Backend Logic:** Code to orchestrate the process: receive form data, call the prompt generator (LLM), call DALL-E with the generated prompt, handle the response (image URL or data), and send it back to the UI.\n",
        "    *   **Azure Services:** Azure OpenAI (for both prompt generation LLM and DALL-E), potentially Azure Blob Storage (to temporarily store or permanently host the generated avatar image, though DALL-E often returns a temporary URL).\n",
        "\n",
        "3.  **Refine the Process Flow:**\n",
        "    *   **User Interaction:** User accesses the \\\"Create Avatar\\\" feature in the chatbot.\n",
        "    *   **UI:** Chatbot presents a form (or a series of questions) asking for preferences.\n",
        "    *   **Data Submission:** User submits the form data to the chatbot backend.\n",
        "    *   **Backend - Prompt Generation:**\n",
        "        *   The backend takes the structured form data.\n",
        "        *   It formats this data into a request for the *prompt-generating* LLM (e.g., `turbogpt`). The request should instruct the LLM to create a detailed DALL-E prompt based on the provided features.\n",
        "        *   The LLM returns a descriptive text prompt (like the example marketing provided).\n",
        "    *   **Backend - Image Generation:**\n",
        "        *   The backend takes the LLM-generated prompt.\n",
        "        *   It makes an API call to the Azure OpenAI DALL-E deployment using this prompt.\n",
        "        *   DALL-E returns a response, typically containing a URL to the generated image (or potentially image data).\n",
        "    *   **Backend - Response Handling:**\n",
        "        *   The backend extracts the image URL from the DALL-E response.\n",
        "        *   *Optional but good practice:* Download the image from the temporary URL and upload it to a more permanent location (like the Azure Blob Storage `avatars` container) to avoid expiry issues. Get the permanent URL.\n",
        "    *   **UI Update:** The backend sends the image URL back to the chatbot frontend. The frontend displays the image as the user's avatar.\n",
        "\n",
        "4.  **Address the \\\"Definition of Done\\\" Items:**\n",
        "\n",
        "    *   **\\\"New chat-gpt model is created (or the old one is used) that will act as a prompt generator...\\\"**: Yes, we need an LLM deployment for this. We *can* reuse the existing `turbogpt` deployment. The key is how we *instruct* it (the system message and user message format) when asking it to generate the DALL-E prompt. No *new* model deployment is strictly *required* if `turbogpt` is suitable.\n",
        "    *   **\\\"Dall-E model deployed in Azure OpenAI instance\\\"**: This is a distinct step. We need to go to Azure OpenAI Studio and deploy a DALL-E model (likely `dall-e-3`).\n",
        "    *   **\\\"Backend implementation is needed...\\\"**: This involves writing Python/JS/C# code to handle the form data, call the prompt-generating LLM, call DALL-E, and manage the image URL.\n",
        "    *   **\\\"Integrated response into chatbot as an avatar...\\\"**: The final step is making the frontend display the received image URL in the designated avatar spot.\n",
        "\n",
        "5.  **Pre-computation/Pre-analysis (Simulating the \\\"Try in Studio First\\\" Tip):**\n",
        "\n",
        "    *   **Prompt Generation in Studio:**\n",
        "        *   Go to Azure OpenAI Studio -> Chat Playground.\n",
        "        *   Select the `turbogpt` deployment.\n",
        "        *   **System Message:** \\\"You are an expert prompt engineer. Create a detailed, descriptive prompt suitable for the DALL-E 3 image generation model based on the user's specified avatar characteristics. Ensure the prompt starts with 'Create me a portrait of...' and incorporates the requested style (e.g., 3D Pixar-like).\\\"\n",
        "        *   **User Message (Example based on form data):**\n",
        "            ```text\n",
        "            Generate a DALL-E prompt for the following avatar features:\n",
        "            Style: 3D Pixar-like\n",
        "            Gender: male\n",
        "            Ethnicity: caucasian\n",
        "            Face Shape: oval, symmetric\n",
        "            Eyebrows: medium thin\n",
        "            Eyes: brown\n",
        "            Beard: 4mm full beard and moustache\n",
        "            Hair: short brown\n",
        "            Clothing: official Manchester United jersey, red baseball cap\n",
        "            ```\n",
        "        *   **Expected Output (from `turbogpt`):** Something very close to the marketing prompt: `\\\"Create me a portrait of 3d Pixar-like style character that will be my avatar. I am caucasian male, have symmetric, oval face with medium thin eyebrows, brown eyes, 4mm full beard and moustache, short brown hair. Avatar is wearing official Manchester United jersey and red baseball cap.\\\"` (Verify this works well).\n",
        "    *   **Image Generation in Studio:**\n",
        "        *   Go to Azure OpenAI Studio -> DALL-E Playground (or Deployments -> Create -> Select `dall-e-3`). Deploy `dall-e-3` if not already done (give it a name, e.g., `dalle3-cinemalytics`).\n",
        "        *   Once deployed, go to the DALL-E Playground.\n",
        "        *   Select the `dalle3-cinemalytics` deployment.\n",
        "        *   Paste the prompt generated in the previous step into the prompt box.\n",
        "        *   Click \\\"Generate\\\".\n",
        "        *   Observe the generated image. Check if it matches the description. Note the response format (usually includes a URL).\n",
        "\n",
        "6.  **Structure the Code Implementation:**\n",
        "\n",
        "    *   **Configuration:** Add new environment variables/settings: `AZURE_OPENAI_DALLE_DEPLOYMENT_NAME`.\n",
        "    *   **Frontend:** Add the HTML form elements (dropdowns, text inputs) for avatar creation. Add JavaScript to capture form data and send it to a new backend endpoint (e.g., `/generate-avatar`). Add logic to display an image when the URL is received back.\n",
        "    *   **Backend:**\n",
        "        *   Create a new API route (e.g., `/generate-avatar`) that accepts POST requests with the form data.\n",
        "        *   Inside the route handler:\n",
        "            *   Parse the incoming form data (JSON).\n",
        "            *   Call a helper function `generate_dalle_prompt(features)` which uses the `turbogpt` deployment (with the specific system message for prompt engineering) to get the DALL-E prompt string.\n",
        "            *   Call a helper function `generate_image(prompt)` which uses the DALL-E deployment (`dalle3-cinemalytics`) to generate the image and return the URL.\n",
        "            *   Return the image URL in the API response (e.g., `{\\\"avatar_url\\\": \\\"...\\\"}`).\n",
        "    *   **Helper Functions:**\n",
        "        *   `generate_dalle_prompt`: Takes a dictionary of features, formats the user message for the LLM, calls `client.chat.completions.create` with the correct system message and user message, extracts the generated prompt text.\n",
        "        *   `generate_image`: Takes the prompt string, calls `client.images.generate` using the DALL-E deployment name, extracts the image URL from the response. Handle potential errors.\n",
        "\n",
        "7.  **Refine and Document:** Add error handling (e.g., what if DALL-E fails? What if the prompt generation fails?). Add comments to the code. Ensure security best practices (don't expose API keys directly in frontend code). Explain the steps clearly in the final response. Use the provided Python example structure as a base. Mention the *need* for frontend changes, even if the detailed code isn't provided (as it depends heavily on the existing chatbot's framework). Emphasize the use of environment variables for secrets. Double-check against the Definition of Done.\"\"\"),\n",
        "                types.Part.from_text(text=\"\"\"Okay, let's tackle Challenge 2! This involves integrating DALL-E for personalized avatar generation based on user input.\n",
        "\n",
        "Here’s the plan, following the scenario and Definition of Done:\n",
        "\n",
        "**Phase 1: Azure OpenAI Setup for DALL-E**\n",
        "\n",
        "1.  **Deploy DALL-E Model:**\n",
        "    *   Navigate back to your Azure OpenAI service in the Azure Portal.\n",
        "    *   Go to **Model deployments** under \\\"Resource Management\\\" and click **Manage Deployments** to open the **Azure OpenAI Studio**.\n",
        "    *   Click **+ Create new deployment**.\n",
        "    *   **Model:** Select a DALL-E model. `dall-e-3` is recommended for better adherence to complex prompts.\n",
        "    *   **Deployment name:** Give it a clear name, for example, `dalle3-cinemalytics`. *Make a note of this exact name.*\n",
        "    *   Click **Create**.\n",
        "\n",
        "    *   **DONE: Dall-E model deployed in Azure OpenAI instance**\n",
        "\n",
        "**Phase 2: Backend Implementation Strategy**\n",
        "\n",
        "We need two core functionalities in the backend:\n",
        "\n",
        "1.  **Prompt Generation:** Take structured user input (from the hypothetical form) and use an LLM (like our existing `turbogpt` deployment) to craft a detailed, high-quality prompt suitable for DALL-E 3.\n",
        "2.  **Image Generation:** Take the generated prompt and send it to the DALL-E 3 deployment to get the image URL.\n",
        "\n",
        "3.  **Configure LLM for Prompt Generation (Using Existing `turbogpt`):**\n",
        "    *   We don't necessarily need a *new* model deployment just for prompt generation. We can reuse the `turbogpt` deployment by providing it with a specific **system message** tailored for this task when we call it.\n",
        "\n",
        "    *   **DONE: New chat-gpt model is created (or the old one is used) that will act as a prompt generator using the avatar features from the chatbot form** (We are choosing to *use the old one* with specific instructions).\n",
        "\n",
        "4.  **Backend Code Implementation (Example - Python):**\n",
        "\n",
        "    *   **Prerequisites:** Ensure your `openai` library is up-to-date (`pip install --upgrade openai`). You'll need the same Azure OpenAI credentials (`ENDPOINT`, `API_KEY`, `API_VERSION`) as before, plus the DALL-E deployment name.\n",
        "    *   **Add Configuration:** Update your configuration (`.env`, `appsettings.json`, etc.) to include the DALL-E deployment name:\n",
        "        ```dotenv\n",
        "        # ... existing variables ...\n",
        "        AZURE_OPENAI_DALLE_DEPLOYMENT_NAME=dalle3-cinemalytics\n",
        "        ```\n",
        "    *   **Implement Backend Logic:** Let's create functions for prompt generation and image generation.\n",
        "\n",
        "        ```python\n",
        "        import os\n",
        "        import json\n",
        "        from openai import AzureOpenAI\n",
        "        from dotenv import load_dotenv\n",
        "\n",
        "        load_dotenv()\n",
        "\n",
        "        # --- Initialize Azure OpenAI Client ---\n",
        "        # Ensure these are loaded correctly from your environment\n",
        "        azure_endpoint = os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\")\n",
        "        api_key = os.getenv(\\\"AZURE_OPENAI_API_KEY\\\")\n",
        "        api_version = os.getenv(\\\"AZURE_OPENAI_API_VERSION\\\") # Use a recent version supporting DALL-E 3\n",
        "        gpt_deployment = os.getenv(\\\"AZURE_OPENAI_DEPLOYMENT_NAME\\\") # e.g., \\\"turbogpt\\\"\n",
        "        dalle_deployment = os.getenv(\\\"AZURE_OPENAI_DALLE_DEPLOYMENT_NAME\\\") # e.g., \\\"dalle3-cinemalytics\\\"\n",
        "\n",
        "        if not all([azure_endpoint, api_key, api_version, gpt_deployment, dalle_deployment]):\n",
        "            raise ValueError(\\\"One or more Azure OpenAI environment variables are missing.\\\")\n",
        "\n",
        "        client = AzureOpenAI(\n",
        "            azure_endpoint=azure_endpoint,\n",
        "            api_key=api_key,\n",
        "            api_version=api_version,\n",
        "        )\n",
        "\n",
        "        # --- Function to Generate DALL-E Prompt using GPT ---\n",
        "        def generate_dalle_prompt_from_features(avatar_features):\n",
        "            \\\"\\\"\\\"\n",
        "            Uses the GPT model to generate a detailed DALL-E prompt based on structured features.\n",
        "\n",
        "            Args:\n",
        "                avatar_features (dict): A dictionary containing user preferences\n",
        "                                        (e.g., {'gender': 'male', 'ethnicity': 'caucasian', ...})\n",
        "\n",
        "            Returns:\n",
        "                str: The generated DALL-E prompt, or None if an error occurs.\n",
        "            \\\"\\\"\\\"\n",
        "            # Convert features dictionary to a string format for the prompt\n",
        "            features_string = \\\"\\\\n\\\".join([f\\\"- {key.replace('_', ' ').capitalize()}: {value}\\\" for key, value in avatar_features.items()])\n",
        "\n",
        "            system_message = \\\"\\\"\\\"You are an expert prompt engineer for the DALL-E 3 image generation model.\n",
        "            Your task is to create a single, detailed, descriptive prompt based on the user's specified avatar characteristics.\n",
        "            Ensure the prompt starts exactly with 'Create me a portrait of...' and incorporates all provided features naturally.\n",
        "            Specify the requested style clearly (e.g., 3D Pixar-like style).\n",
        "            Be specific about details like hair length/color, facial features, clothing, and accessories.\n",
        "            The output should be ONLY the DALL-E prompt itself, without any introduction or explanation.\\\"\\\"\\\"\n",
        "\n",
        "            user_message = f\\\"\\\"\\\"Generate a DALL-E 3 prompt for an avatar with the following features:\n",
        "            {features_string}\\\"\\\"\\\"\n",
        "\n",
        "            print(f\\\"--- Sending request to GPT for prompt generation ---\\\")\n",
        "            print(f\\\"System Message: {system_message}\\\")\n",
        "            print(f\\\"User Message:\\\\n{user_message}\\\")\n",
        "\n",
        "\n",
        "            try:\n",
        "                response = client.chat.completions.create(\n",
        "                    model=gpt_deployment, # Use the GPT deployment\n",
        "                    messages=[\n",
        "                        {\\\"role\\\": \\\"system\\\", \\\"content\\\": system_message},\n",
        "                        {\\\"role\\\": \\\"user\\\", \\\"content\\\": user_message}\n",
        "                    ],\n",
        "                    temperature=0.5, # Lower temperature for more deterministic prompt generation\n",
        "                    max_tokens=300\n",
        "                )\n",
        "                generated_prompt = response.choices[0].message.content.strip()\n",
        "                print(f\\\"--- Received DALL-E prompt from GPT ---\\\\n{generated_prompt}\\\")\n",
        "                return generated_prompt\n",
        "            except Exception as e:\n",
        "                print(f\\\"An error occurred during prompt generation: {e}\\\")\n",
        "                return None\n",
        "\n",
        "        # --- Function to Generate Image using DALL-E ---\n",
        "        def generate_avatar_image(prompt):\n",
        "            \\\"\\\"\\\"\n",
        "            Generates an image using the DALL-E deployment based on the provided prompt.\n",
        "\n",
        "            Args:\n",
        "                prompt (str): The detailed prompt for DALL-E.\n",
        "\n",
        "            Returns:\n",
        "                str: The URL of the generated image, or None if an error occurs.\n",
        "            \\\"\\\"\\\"\n",
        "            print(f\\\"--- Sending request to DALL-E ---\\\")\n",
        "            print(f\\\"Prompt: {prompt}\\\")\n",
        "\n",
        "            try:\n",
        "                # Note: DALL-E 3 only supports n=1 and specific sizes like 1024x1024\n",
        "                result = client.images.generate(\n",
        "                    model=dalle_deployment, # Use the DALL-E deployment name\n",
        "                    prompt=prompt,\n",
        "                    n=1,\n",
        "                    size=\\\"1024x1024\\\", # DALL-E 3 supports 1024x1024, 1792x1024, 1024x1792\n",
        "                    # quality=\\\"hd\\\", # Optional: use 'hd' for enhanced detail\n",
        "                    # style=\\\"vivid\\\" # Optional: use 'vivid' or 'natural'\n",
        "                )\n",
        "\n",
        "                # DALL-E 3 response structure might differ slightly, adjust as needed\n",
        "                # Typically found in result.data[0].url\n",
        "                json_response = json.loads(result.model_dump_json())\n",
        "                image_url = json_response[\\\"data\\\"][0][\\\"url\\\"] # Accessing the URL safely\n",
        "\n",
        "                print(f\\\"--- Received Image URL from DALL-E ---\\\\n{image_url}\\\")\n",
        "                return image_url\n",
        "            except Exception as e:\n",
        "                print(f\\\"An error occurred during image generation: {e}\\\")\n",
        "                return None\n",
        "\n",
        "        # --- Example Usage (Simulating receiving form data) ---\n",
        "        if __name__ == \\\"__main__\\\":\n",
        "            # Simulate data coming from the chatbot's form\n",
        "            # These keys should match what your frontend form sends\n",
        "            user_avatar_preferences = {\n",
        "                \\\"style\\\": \\\"3D Pixar-like style\\\",\n",
        "                \\\"gender\\\": \\\"male\\\",\n",
        "                \\\"ethnicity\\\": \\\"caucasian\\\",\n",
        "                \\\"face_shape\\\": \\\"symmetric, oval face\\\",\n",
        "                \\\"eyebrows\\\": \\\"medium thin eyebrows\\\",\n",
        "                \\\"eyes\\\": \\\"brown eyes\\\",\n",
        "                \\\"beard\\\": \\\"4mm full beard and moustache\\\",\n",
        "                \\\"hair\\\": \\\"short brown hair\\\",\n",
        "                \\\"clothing\\\": \\\"official Manchester United jersey\\\",\n",
        "                \\\"accessories\\\": \\\"red baseball cap\\\"\n",
        "            }\n",
        "\n",
        "            # 1. Generate the DALL-E prompt\n",
        "            dalle_prompt = generate_dalle_prompt_from_features(user_avatar_preferences)\n",
        "\n",
        "            if dalle_prompt:\n",
        "                 # 2. Generate the image using the prompt\n",
        "                 avatar_url = generate_avatar_image(dalle_prompt)\n",
        "\n",
        "                 if avatar_url:\n",
        "                     print(f\\\"\\\\nSuccessfully generated avatar!\\\")\n",
        "                     print(f\\\"Avatar Image URL: {avatar_url}\\\")\n",
        "                     # In a real application, this URL would be sent back\n",
        "                     # to the frontend to display the image.\n",
        "                 else:\n",
        "                     print(\\\"\\\\nFailed to generate avatar image.\\\")\n",
        "            else:\n",
        "                print(\\\"\\\\nFailed to generate DALL-E prompt.\\\")\n",
        "\n",
        "        ```\n",
        "\n",
        "    *   **Integration Point:** In your actual chatbot backend (Flask, Django, Express, ASP.NET Core, etc.), you would create an API endpoint (e.g., `/api/generate-avatar`). This endpoint would:\n",
        "        *   Receive the `user_avatar_preferences` dictionary (as JSON) in the request body from the frontend form submission.\n",
        "        *   Call `generate_dalle_prompt_from_features()` with this data.\n",
        "        *   If successful, call `generate_avatar_image()` with the resulting prompt.\n",
        "        *   Return the `avatar_url` in the JSON response to the frontend.\n",
        "\n",
        "    *   **DONE: Backend implementation is needed and data from input form on chatbot UI will be used to generate the prompt. Generated prompt will then be sent to the Dall-E image generator.** (The Python code provides the core logic).\n",
        "\n",
        "**Phase 3: Frontend Integration**\n",
        "\n",
        "5.  **Integrate Response into Chatbot UI:**\n",
        "    *   **Frontend Form:** You need to build the actual HTML form in your chatbot's UI to collect the preferences (gender, ethnicity, hair color, etc.). Use standard HTML elements like `<select>`, `<input type=\\\"text\\\">`, `<input type=\\\"radio\\\">`.\n",
        "    *   **Frontend JavaScript:**\n",
        "        *   Add JavaScript to capture the values from the form when the user submits it.\n",
        "        *   Package these values into a JSON object (like `user_avatar_preferences` in the example).\n",
        "        *   Use `fetch` or a similar library (e.g., `axios`) to send a POST request to your backend endpoint (e.g., `/api/generate-avatar`) with the JSON data.\n",
        "        *   Handle the response from the backend. If successful, it will contain the `avatar_url`.\n",
        "        *   Use JavaScript to update an `<img>` tag in your chatbot interface, setting its `src` attribute to the received `avatar_url`. This will display the generated avatar. You might also want to show a loading indicator while waiting for the image.\n",
        "\n",
        "    *   **DONE: Integrated response into chatbot as an avatar to personalize application** (This describes the necessary frontend steps, though the specific code depends on the chatbot's framework).\n",
        "\n",
        "**Conclusion for Challenge 2**\n",
        "\n",
        "Your chatbot now has a powerful personalization feature! Users can define their desired avatar characteristics through a form. The backend intelligently uses GPT-3.5/4 (`turbogpt`) to craft a detailed DALL-E prompt based on these inputs and then calls the DALL-E 3 deployment (`dalle3-cinemalytics`) to generate the image. Finally, the generated avatar is displayed back to the user within the chatbot interface, creating a much more engaging and personalized experience. Remember to handle potential errors gracefully (e.g., if image generation fails or takes too long) in your production implementation.\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Made a connection to the database programatically\n",
        "Integrated chatbot with deployment that can talk to the database\n",
        "Made a query to the database thru the chatbot:\n",
        "\\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\"\n",
        "Created queries:\n",
        "Fetch top 10 customers with most total orders and customer names in one table\n",
        "Fetch top 20 most watched movies from order details and their titles in one table\n",
        "Hints (if you choose dotnet)\n",
        "Clone the GitHub repository locally (resource 2)\n",
        "Scaffold the dbcontext and models using EF tool (follow the tutorial in resource 4)\n",
        "Add SQL Server EF package to your project (Microsoft.EntityFrameworkCore.SqlServer)\n",
        "Copy the content from the MovieSalesDbContext.cs to Data/AppDbContext.cs but keep these two methods:\n",
        "\n",
        "Remove the warning content (it contains connection string which shouldn't be there)\n",
        "Remove existing models from Data/Models folder\n",
        "Copy scaffolded models from your folder to Data/Models folder\n",
        "Change the namespace in your models to AnthonyPuppo.SemanticKernel.NL2EF.Data.Models\n",
        "Add the correct connection string in Program.cs so that you app can connect to the database:\n",
        "\n",
        "Resources\n",
        "Dotnet\n",
        "semantic-kernel/dotnet/README.md at main · microsoft/semantic-kernel (github.com)\n",
        "anthonypuppo/sk-nl2ef-plugin: A ChatGPT plugin built with Semantic Kernel that queries a database via natural language\n",
        "Natural Language to SQL | Semantic Kernel Plugins Hackathon #1 Winner! - YouTube\n",
        "Reverse Engineering - EF Core | Microsoft Learn\n",
        "JavaScript\n",
        "Installation | 🦜️🔗 Langchain\n",
        "Python\n",
        "https://github.com/pablomarin/GPT-Azure-Search-Engine/blob/main/08-SQLDB_QA.ipynb\n",
        "REST API\n",
        "https://devblogs.microsoft.com/azure-sql/using-openai-rest-endpoints-with-azure-sql-database/\n",
        "\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"model\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Here's a thinking process that leads to the comprehensive C#/.NET solution for the NL2SQL challenge:\n",
        "\n",
        "1.  **Understand the Goal:** The core task is to enable a chatbot, powered by Azure OpenAI, to understand natural language questions about data in a SQL Server database, translate those questions into SQL queries, execute them, and return the results to the user. The specific hints point towards using .NET, Semantic Kernel, and Entity Framework Core (EF Core).\n",
        "\n",
        "2.  **Identify Key Components:**\n",
        "    *   **Natural Language Input:** User asks a question like \\\"Show me top customers\\\".\n",
        "    *   **Translation Layer (NL2SQL):** Something needs to convert the natural language question into a valid SQL query. This is where Semantic Kernel comes in.\n",
        "    *   **Database Interaction Layer:** Something needs to execute the generated SQL query against the actual database. EF Core is the recommended tool here.\n",
        "    *   **Large Language Model (LLM):** Azure OpenAI (specifically the `turbogpt` deployment) is needed by Semantic Kernel to understand the natural language and generate the SQL.\n",
        "    *   **Database:** An existing SQL Server database (the hints imply one exists, likely related to movie sales/orders).\n",
        "    *   **Chatbot Framework:** The existing chatbot application needs to integrate these new components.\n",
        "\n",
        "3.  **Leverage Provided Resources and Hints (.NET Focus):**\n",
        "    *   **Resource 2 (AnthonyPuppo/sk-nl2ef-plugin):** This repository is *crucial*. It's a direct example of using Semantic Kernel (SK) with EF Core for NL2SQL. This will be the primary reference.\n",
        "    *   **Resource 4 (EF Core Reverse Engineering):** Explains how to generate EF Core models (`DbSet` properties and entity classes) from an existing database schema. This is necessary to interact with the database using C#.\n",
        "    *   **Hint: Clone the repo:** Start by getting the example code locally.\n",
        "    *   **Hint: Scaffold `DbContext`:** Use the `dotnet ef dbcontext scaffold` command. This requires the database connection string and EF Core tools (`dotnet tool install --global dotnet-ef`).\n",
        "    *   **Hint: Add SQL Server EF package:** `dotnet add package Microsoft.EntityFrameworkCore.SqlServer`.\n",
        "    *   **Hint: Copy/Merge `DbContext`:** Integrate the *scaffolded* `DbContext` into the example project's structure, keeping essential methods from the example's original `DbContext`. This suggests the example project already has some structure or helper methods related to SK integration.\n",
        "    *   **Hint: Handle Connection String:** Remove hardcoded strings from the scaffolded context and configure it properly in `Program.cs` (or `appsettings.json` read by `Program.cs`).\n",
        "    *   **Hint: Copy/Move Models:** Replace the example models with the newly scaffolded ones, ensuring the namespace matches the project structure.\n",
        "\n",
        "4.  **Outline the Implementation Steps (Following Hints):**\n",
        "\n",
        "    *   **Step 0: Prerequisites:** Install .NET SDK, EF Core tools. Have Azure OpenAI details (endpoint, key, deployment name) and the SQL Server connection string ready.\n",
        "    *   **Step 1: Setup Project:**\n",
        "        *   Clone the `sk-nl2ef-plugin` repository.\n",
        "        *   Open it in an IDE (like Visual Studio or VS Code).\n",
        "        *   Add the `Microsoft.EntityFrameworkCore.SqlServer` package.\n",
        "    *   **Step 2: Database Connection & Scaffolding:**\n",
        "        *   Identify the target SQL Server database and get its connection string.\n",
        "        *   Run `dotnet ef dbcontext scaffold \\\"YourConnectionString\\\" Microsoft.EntityFrameworkCore.SqlServer --output-dir Data/ScaffoldedModels --context YourDbContextName --context-dir Data --data-annotations --force` (adjust paths and names as needed). The `--force` overwrites existing files if run multiple times. `--data-annotations` adds validation attributes based on the schema.\n",
        "    *   **Step 3: Integrate Scaffolded Code:**\n",
        "        *   Examine the scaffolded `YourDbContextName.cs` and the existing `Data/AppDbContext.cs` in the cloned project.\n",
        "        *   *Merge:* Copy the `DbSet<>` properties from the *scaffolded* context into `AppDbContext.cs`.\n",
        "        *   *Keep Methods:* Retain any helper methods present in the original `AppDbContext.cs` (like `GetDbContextSchema` mentioned in the Puppo repo, which is vital for SK).\n",
        "        *   *Remove Warning:* Delete the `#warning` block containing the connection string from the scaffolded (or now merged) `AppDbContext.cs`.\n",
        "        *   *Move Models:* Delete the contents of `Data/Models`. Copy the entity classes (`.cs` files) from `Data/ScaffoldedModels` into `Data/Models`.\n",
        "        *   *Fix Namespaces:* Ensure all classes in `Data/Models` have the namespace `AnthonyPuppo.SemanticKernel.NL2EF.Data.Models` (or whatever the target project's namespace is).\n",
        "    *   **Step 4: Configure Connection String:**\n",
        "        *   Locate where the `DbContext` is registered in `Program.cs` (usually in `builder.Services.AddDbContext<AppDbContext>(...)`).\n",
        "        *   Replace any placeholder connection string logic with the actual connection string, ideally loaded from configuration (`appsettings.json` or environment variables).\n",
        "        *   Example `appsettings.json`:\n",
        "            ```json\n",
        "            {\n",
        "              \\\"ConnectionStrings\\\": {\n",
        "                \\\"DefaultConnection\\\": \\\"Your_SQL_Server_Connection_String\\\"\n",
        "              },\n",
        "              \\\"AzureOpenAI\\\": {\n",
        "                 \\\"Endpoint\\\": \\\"YOUR_AOAI_ENDPOINT\\\",\n",
        "                 \\\"ApiKey\\\": \\\"YOUR_AOAI_KEY\\\",\n",
        "                 \\\"ChatDeploymentName\\\": \\\"turbogpt\\\"\n",
        "              }\n",
        "              // ... other settings\n",
        "            }\n",
        "            ```\n",
        "        *   Example `Program.cs`:\n",
        "            ```csharp\n",
        "            var connectionString = builder.Configuration.GetConnectionString(\\\"DefaultConnection\\\");\n",
        "            builder.Services.AddDbContext<AppDbContext>(options =>\n",
        "                options.UseSqlServer(connectionString));\n",
        "            ```\n",
        "    *   **Step 5: Configure Semantic Kernel:**\n",
        "        *   Locate the Semantic Kernel setup in `Program.cs` or a related service configuration file.\n",
        "        *   Ensure it's configured with the Azure OpenAI Endpoint, API Key, and the *correct chat deployment name* (`turbogpt`).\n",
        "        *   Verify that the `NL2EFPlugin` (or similar name from the cloned repo) is being registered with the Kernel. This plugin likely contains the core logic:\n",
        "            *   Takes natural language input.\n",
        "            *   Uses a semantic function (with a prompt telling the LLM to generate SQL) leveraging the database schema provided by `AppDbContext.GetDbContextSchema()`.\n",
        "            *   Executes the generated SQL using the `AppDbContext`.\n",
        "    *   **Step 6: Integrate with Chatbot:**\n",
        "        *   Modify the chatbot's core logic (where it handles user messages).\n",
        "        *   When a user asks a question that seems database-related (this might require some intent detection or a specific keyword), invoke the Semantic Kernel function responsible for NL2SQL.\n",
        "        *   Pass the user's query (e.g., \\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\") to the SK function.\n",
        "        *   The SK function (via the plugin) interacts with the LLM and EF Core.\n",
        "        *   Receive the results (likely formatted text or structured data) back from the SK function.\n",
        "        *   Display the results to the user in the chatbot interface.\n",
        "    *   **Step 7: Testing:**\n",
        "        *   Run the chatbot application.\n",
        "        *   Test the specific queries mentioned in the DoD:\n",
        "            *   \\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\"\n",
        "            *   \\\"Fetch top 10 customers with most total orders and customer names in one table\\\"\n",
        "            *   \\\"Fetch top 20 most watched movies from order details and their titles in one table\\\" (This one is tricky - it requires joins between Orders, OrderDetails, and potentially a Movies table. The quality of the generated SQL depends heavily on the schema provided to the LLM and the LLM's capabilities).\n",
        "        *   Debug any errors (connection issues, incorrect SQL generation, SK configuration problems).\n",
        "\n",
        "5.  **Refine the .NET Code Structure (Self-Correction/Improvements):**\n",
        "    *   Ensure proper dependency injection is used for `AppDbContext` and the Semantic Kernel services/plugins.\n",
        "    *   Use `async/await` consistently for database and LLM calls.\n",
        "    *   Add error handling (e.g., what happens if the generated SQL is invalid? What if the database connection fails?).\n",
        "    *   Consider security: Ensure the generated SQL isn't vulnerable to injection (though using EF Core often mitigates direct SQL injection, validating the *intent* and *scope* of the generated query is still important). Parameterization is key if raw SQL is ever executed.\n",
        "    *   Make configuration external (use `appsettings.json` and user secrets).\n",
        "\n",
        "6.  **Final Output Generation:** Structure the answer clearly, following the DoD items. Provide code snippets for the key integration points (Program.cs configuration, invoking the SK function). Explain *why* each step is necessary, referencing the hints and resources. Acknowledge potential challenges (e.g., complex query generation).\"\"\"),\n",
        "                types.Part.from_text(text=\"\"\"Okay, this challenge dives into the exciting world of Natural Language to SQL (NL2SQL), leveraging Semantic Kernel and Entity Framework Core within a .NET context, as strongly suggested by the hints and resources.\n",
        "\n",
        "Let's break down the steps to achieve the Definition of Done using the provided .NET hints.\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "1.  You have an existing SQL Server database containing relevant tables (like `Orders`, `Customers`, `OrderDetails`, `Movies`).\n",
        "2.  You have the connection string for this database.\n",
        "3.  You have your Azure OpenAI endpoint, API key, and the `turbogpt` deployment name ready.\n",
        "4.  You have the .NET SDK (6, 7, or 8) and Entity Framework Core tools installed (`dotnet tool install --global dotnet-ef`).\n",
        "5.  You are working within the context of the chatbot application you've been building, potentially integrating this new functionality.\n",
        "\n",
        "**Phase 1: Project Setup and Database Integration**\n",
        "\n",
        "1.  **Clone the Reference Repository:**\n",
        "    *   Clone Anthony Puppo's Semantic Kernel NL2EF plugin repository, as it provides a working structure:\n",
        "        ```bash\n",
        "        git clone https://github.com/anthonypuppo/sk-nl2ef-plugin.git\n",
        "        cd sk-nl2ef-plugin\n",
        "        ```\n",
        "    *   Open this project in your preferred IDE (Visual Studio / VS Code). This will serve as our base for integrating *your* database.\n",
        "\n",
        "2.  **Add EF Core SQL Server Package:**\n",
        "    *   Ensure the project targets the correct .NET version if necessary.\n",
        "    *   Add the required package via NuGet Package Manager or command line:\n",
        "        ```bash\n",
        "        dotnet add package Microsoft.EntityFrameworkCore.SqlServer\n",
        "        ```\n",
        "\n",
        "3.  **Scaffold DbContext and Models:**\n",
        "    *   This is the crucial step to make EF Core aware of *your* database schema. Run the EF Core tools command. Replace `\\\"YourConnectionString\\\"` with your actual SQL Server connection string. Choose a suitable name for your context (e.g., `CinemalyticsDbContext`) and specify output directories as suggested by the hints.\n",
        "        ```bash\n",
        "        # Replace connection string, context name, and potentially adjust paths slightly\n",
        "        dotnet ef dbcontext scaffold \\\"Server=your_server;Database=your_database;User ID=your_user;Password=your_password;Encrypt=true;TrustServerCertificate=false;\\\" Microsoft.EntityFrameworkCore.SqlServer --context CinemalyticsDbContext --context-dir Data --output-dir Data/ScaffoldedModels --data-annotations --force\n",
        "        ```\n",
        "        *   `--context`: Specifies the name of the DbContext class to generate.\n",
        "        *   `--context-dir`: Where to put the DbContext file.\n",
        "        *   `--output-dir`: Where to put the generated entity model classes.\n",
        "        *   `--data-annotations`: Adds attributes like `[Key]`, `[Required]`, `[MaxLength]` based on the schema.\n",
        "        *   `--force`: Overwrites existing files if you run it again.\n",
        "\n",
        "4.  **Integrate Scaffolded Code into Project Structure:**\n",
        "    *   **Merge DbContext:**\n",
        "        *   Open the newly generated `Data/CinemalyticsDbContext.cs` (or whatever you named it).\n",
        "        *   Open the existing `Data/AppDbContext.cs` from the cloned repository.\n",
        "        *   *Copy* all the `public virtual DbSet<YourModel> YourModels { get; set; }` properties from `CinemalyticsDbContext.cs` into `AppDbContext.cs`.\n",
        "        *   *Keep* the existing constructor and the `GetDbContextSchema()` method from the original `AppDbContext.cs`. This schema method is vital for Semantic Kernel to understand your database structure.\n",
        "        *   You can now potentially delete the generated `CinemalyticsDbContext.cs` file if `AppDbContext.cs` contains everything needed.\n",
        "    *   **Remove Warning:** In `AppDbContext.cs`, delete the `#warning To protect potentially sensitive information...` block and the `OnConfiguring` method if it was scaffolded (we will configure the connection in `Program.cs`).\n",
        "    *   **Replace Models:**\n",
        "        *   Delete all existing model files (e.g., `Order.cs`, `Product.cs`) inside the `Data/Models` folder of the cloned project.\n",
        "        *   Move all the generated entity class files (`.cs` files) from `Data/ScaffoldedModels` into the `Data/Models` folder.\n",
        "    *   **Adjust Namespaces:**\n",
        "        *   Open each model file you just moved into `Data/Models`.\n",
        "        *   Change the namespace at the top to match the project's expected namespace, likely: `AnthonyPuppo.SemanticKernel.NL2EF.Data.Models` (or adjust if you renamed the base project).\n",
        "\n",
        "5.  **Configure Connection String in `Program.cs`:**\n",
        "    *   Open `Program.cs` (or potentially `Startup.cs` in older .NET versions).\n",
        "    *   Locate the `builder.Services.AddDbContext<AppDbContext>(...)` line.\n",
        "    *   Modify it to read the connection string from configuration (`appsettings.json` or environment variables) instead of any hardcoded value.\n",
        "\n",
        "    *   **Add to `appsettings.json`:**\n",
        "        ```json\n",
        "        {\n",
        "          \\\"ConnectionStrings\\\": {\n",
        "            \\\"DefaultConnection\\\": \\\"Server=your_server;Database=your_database;User ID=your_user;Password=your_password;Encrypt=true;TrustServerCertificate=false;\\\"\n",
        "          },\n",
        "          \\\"AzureOpenAI\\\": {\n",
        "            \\\"Endpoint\\\": \\\"YOUR_AZURE_OPENAI_ENDPOINT\\\",\n",
        "            \\\"ApiKey\\\": \\\"YOUR_AZURE_OPENAI_API_KEY\\\",\n",
        "            \\\"ChatDeploymentName\\\": \\\"turbogpt\\\" // Your GPT deployment\n",
        "          }\n",
        "          // ... other settings\n",
        "        }\n",
        "        ```\n",
        "        *Make sure to use User Secrets or another secure method for sensitive data like passwords and API keys in production.*\n",
        "\n",
        "    *   **Modify `Program.cs`:**\n",
        "        ```csharp\n",
        "        // Add necessary using statements if missing\n",
        "        using Microsoft.EntityFrameworkCore;\n",
        "        using AnthonyPuppo.SemanticKernel.NL2EF.Data; // Namespace for AppDbContext\n",
        "\n",
        "        var builder = WebApplication.CreateBuilder(args);\n",
        "\n",
        "        // ... other services (like Controllers, Swagger)\n",
        "\n",
        "        // Configure DbContext\n",
        "        var connectionString = builder.Configuration.GetConnectionString(\\\"DefaultConnection\\\");\n",
        "        builder.Services.AddDbContext<AppDbContext>(options =>\n",
        "            options.UseSqlServer(connectionString)); // Use the connection string from config\n",
        "\n",
        "        // Configure Semantic Kernel (ensure this section exists and reads from config)\n",
        "        builder.Services.AddSingleton<IKernel>(sp =>\n",
        "        {\n",
        "            var config = sp.GetRequiredService<IConfiguration>();\n",
        "            var kernel = Kernel.Builder\n",
        "                .WithAzureChatCompletionService(\n",
        "                    config[\\\"AzureOpenAI:ChatDeploymentName\\\"],\n",
        "                    config[\\\"AzureOpenAI:Endpoint\\\"],\n",
        "                    config[\\\"AzureOpenAI:ApiKey\\\"])\n",
        "                .Build();\n",
        "\n",
        "            // Register the NL2EF Plugin (assuming it's structured as a plugin)\n",
        "            var nl2efPlugin = new NL2EFPlugin(sp.GetRequiredService<AppDbContext>());\n",
        "            kernel.ImportFunctions(nl2efPlugin, \\\"NL2EF\\\"); // Import the plugin functions\n",
        "\n",
        "            return kernel;\n",
        "        });\n",
        "\n",
        "\n",
        "        // Add the NL2EFPlugin itself if it needs DI or specific registration\n",
        "        // builder.Services.AddScoped<NL2EFPlugin>(); // Or Singleton/Transient depending on its design\n",
        "\n",
        "        // ... rest of Program.cs (app build, pipeline config)\n",
        "\n",
        "        var app = builder.Build();\n",
        "\n",
        "        // ... configure middleware (Swagger, HTTPS, Auth, Routing)\n",
        "\n",
        "        app.MapControllers(); // Make sure controllers are mapped if using API controllers\n",
        "\n",
        "        app.Run();\n",
        "        ```\n",
        "        *(Note: The exact Semantic Kernel setup might vary slightly based on the version and the structure in the cloned repo. Adapt the `.WithAzureChatCompletionService` and plugin registration accordingly. The key is providing the Azure OpenAI details and registering the plugin that uses the `AppDbContext`)*.\n",
        "\n",
        "    *   **DONE: Made a connection to the database programmatically**\n",
        "\n",
        "**Phase 2: Chatbot Integration and Querying**\n",
        "\n",
        "6.  **Integrate Chatbot with NL2SQL Deployment:**\n",
        "    *   Your chatbot application now needs to call the Semantic Kernel function responsible for handling natural language database queries. This usually involves:\n",
        "        *   An API endpoint in your chatbot backend (if it's separate) or directly within the application (if monolithic).\n",
        "        *   Injecting the `IKernel` instance into the service or controller handling chat messages.\n",
        "        *   Invoking the specific Semantic Kernel function from the imported `NL2EFPlugin`.\n",
        "\n",
        "    *   **Example (inside an API Controller or Service):**\n",
        "        ```csharp\n",
        "        using Microsoft.AspNetCore.Mvc;\n",
        "        using Microsoft.SemanticKernel;\n",
        "        using Microsoft.SemanticKernel.Orchestration; // For SKContext/ContextVariables\n",
        "\n",
        "        [ApiController]\n",
        "        [Route(\\\"api/[controller]\\\")]\n",
        "        public class ChatController : ControllerBase\n",
        "        {\n",
        "            private readonly IKernel _kernel;\n",
        "            private readonly ILogger<ChatController> _logger;\n",
        "\n",
        "            public ChatController(IKernel kernel, ILogger<ChatController> logger)\n",
        "            {\n",
        "                _kernel = kernel;\n",
        "                _logger = logger;\n",
        "            }\n",
        "\n",
        "            [HttpPost(\\\"query-database\\\")]\n",
        "            public async Task<IActionResult> QueryDatabase([FromBody] UserQueryRequest request)\n",
        "            {\n",
        "                if (string.IsNullOrWhiteSpace(request.Query))\n",
        "                {\n",
        "                    return BadRequest(\\\"Query cannot be empty.\\\");\n",
        "                }\n",
        "\n",
        "                try\n",
        "                {\n",
        "                    _logger.LogInformation(\\\"Received database query: {Query}\\\", request.Query);\n",
        "\n",
        "                    // Assume the NL2EFPlugin has a function named \\\"QueryDatabase\\\"\n",
        "                    var function = _kernel.Functions.GetFunction(\\\"NL2EF\\\", \\\"QueryDatabase\\\");\n",
        "\n",
        "                    var variables = new ContextVariables(request.Query);\n",
        "                    variables.Set(\\\"input\\\", request.Query); // Set the input variable for the function\n",
        "\n",
        "                    // Invoke the Semantic Kernel function\n",
        "                    var result = await _kernel.RunAsync(function, variables);\n",
        "\n",
        "                    // Check for errors potentially captured by SK\n",
        "                    if (result.ErrorOccurred)\n",
        "                    {\n",
        "                        _logger.LogError(\\\"Semantic Kernel execution failed: {ErrorMessage}\\\", result.LastErrorDescription);\n",
        "                         return StatusCode(500, $\\\"Error processing query: {result.LastErrorDescription}\\\");\n",
        "                    }\n",
        "\n",
        "                    var queryResult = result.GetValue<string>(); // Or potentially a structured object if the plugin returns one\n",
        "\n",
        "                    _logger.LogInformation(\\\"Query successful. Result: {Result}\\\", queryResult);\n",
        "\n",
        "                    // Return the result obtained from the database via SK/EF Core\n",
        "                    return Ok(new { Answer = queryResult });\n",
        "                }\n",
        "                catch (Exception ex)\n",
        "                {\n",
        "                    _logger.LogError(ex, \\\"An unexpected error occurred while querying the database.\\\");\n",
        "                    return StatusCode(500, \\\"An internal server error occurred.\\\");\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        // Simple request model\n",
        "        public class UserQueryRequest\n",
        "        {\n",
        "            public string Query { get; set; }\n",
        "        }\n",
        "        ```\n",
        "        *(Note: The function name `\\\"QueryDatabase\\\"` and plugin name `\\\"NL2EF\\\"` must match how they are defined and imported in `Program.cs` and within the plugin class itself. The result parsing (`result.GetValue<string>()`) might need adjustment based on what the plugin actually returns).*\n",
        "\n",
        "    *   **DONE: Integrated chatbot with deployment that can talk to the database**\n",
        "\n",
        "7.  **Perform Queries through Chatbot:**\n",
        "    *   Run your chatbot application.\n",
        "    *   Interact with the chatbot interface and send the specific natural language queries to the endpoint you created (e.g., `/api/chat/query-database`).\n",
        "\n",
        "    *   **Query 1:** `\\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\"`\n",
        "        *   *Expected Behavior:* Semantic Kernel should use the `turbogpt` model and the database schema to understand this request. It should generate an appropriate SQL query (likely involving `SELECT TOP 10 CustomerID, COUNT(*) FROM dbo.Orders GROUP BY CustomerID` or similar, though the exact SQL might vary). EF Core executes this, and the plugin returns the results (perhaps formatted as text or JSON). The chatbot displays this.\n",
        "    *   **DONE: Made a query to the database thru the chatbot: \\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\"**\n",
        "\n",
        "    *   **Query 2:** `\\\"Fetch top 10 customers with most total orders and customer names in one table\\\"`\n",
        "        *   *Expected Behavior:* This requires joining `Customers` and `Orders` tables, grouping by customer, counting orders, ordering, and taking the top 10. SK needs to generate a query like:\n",
        "            ```sql\n",
        "            SELECT TOP 10 c.CustomerID, c.CustomerName, COUNT(o.OrderID) AS OrderCount\n",
        "            FROM Customers c -- Assuming 'CustomerName' is a column\n",
        "            JOIN Orders o ON c.CustomerID = o.CustomerID\n",
        "            GROUP BY c.CustomerID, c.CustomerName\n",
        "            ORDER BY OrderCount DESC;\n",
        "            ```\n",
        "            The results (CustomerID, Name, Count) are returned and displayed.\n",
        "    *   **DONE: Created queries: Fetch top 10 customers with most total orders and customer names in one table**\n",
        "\n",
        "    *   **Query 3:** `\\\"Fetch top 20 most watched movies from order details and their titles in one table\\\"`\n",
        "        *   *Expected Behavior:* This is the most complex. It likely requires joining `OrderDetails`, `Movies` (assuming `OrderDetails` links to a `MovieID` and you have a `Movies` table with `MovieID` and `Title`), grouping by movie, summing quantities or counting occurrences, ordering, and taking the top 20. SK needs to generate something like:\n",
        "            ```sql\n",
        "            SELECT TOP 20 m.MovieID, m.Title, SUM(od.Quantity) AS TotalWatched -- Or COUNT(*) depending on schema/intent\n",
        "            FROM OrderDetails od\n",
        "            JOIN Movies m ON od.MovieID = m.MovieID -- Assuming these tables/columns exist\n",
        "            GROUP BY m.MovieID, m.Title\n",
        "            ORDER BY TotalWatched DESC;\n",
        "            ```\n",
        "            The results (MovieID, Title, Count/Sum) are returned and displayed. The success of this heavily depends on how well the database schema (`GetDbContextSchema()`) describes these relationships and the LLM's ability to infer the joins and aggregations.\n",
        "    *   **DONE: Created queries: Fetch top 20 most watched movies from order details and their titles in one table**\n",
        "\n",
        "**Conclusion for Challenge 3 (.NET)**\n",
        "\n",
        "You have successfully integrated natural language database querying into your chatbot using .NET, Semantic Kernel, Entity Framework Core, and Azure OpenAI. You've scaffolded your specific database schema, configured the connection, set up Semantic Kernel with the NL2EF plugin, and created an endpoint in your chatbot backend to handle these queries. Users can now ask questions in plain English about their movie data, and the system translates these into SQL, executes them, and returns the results. This significantly enhances the chatbot's capabilities for data exploration.\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"use python\n",
        "\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"model\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"Here's a thinking process for generating the Python-based NL2SQL solution:\n",
        "\n",
        "1.  **Understand the Goal:** The core requirement is to enable a Python chatbot to answer questions by querying a SQL database using natural language. This involves translating natural language to SQL, executing the SQL, and presenting the results.\n",
        "\n",
        "2.  **Identify Key Technologies (Python Context):**\n",
        "    *   **Natural Language Understanding & SQL Generation:** Need a Large Language Model (LLM). Azure OpenAI (`gpt-3.5-turbo` or `gpt-4`) is specified.\n",
        "    *   **Database Interaction:** Need a Python library to connect to and query a SQL database (e.g., SQL Server, PostgreSQL, MySQL). Common choices include `pyodbc`, `psycopg2`, `mysql-connector-python`, or higher-level ORMs like SQLAlchemy. SQLAlchemy is often preferred for abstraction and compatibility.\n",
        "    *   **Orchestration/Framework:** How to tie the LLM and database interaction together?\n",
        "        *   *LangChain:* Explicitly mentioned in the resources and very popular for RAG/Agent patterns, including NL2SQL. It has specific SQL agents/chains. This seems like the most direct path.\n",
        "        *   *Semantic Kernel (Python):* While the previous request focused on .NET Semantic Kernel, the Python version also exists. It offers similar concepts (skills, planners) but might be less mature or have fewer readily available SQL examples compared to LangChain's dedicated SQL tools *at the time of writing*.\n",
        "        *   *Manual Implementation:* Possible, but requires more effort in prompt engineering, parsing LLM output, error handling, and security.\n",
        "    *   **Decision:** LangChain seems the most appropriate choice given the prompt's resources and the typical Python ecosystem for this task. It provides pre-built components specifically for SQL interaction.\n",
        "\n",
        "3.  **Outline the Steps (LangChain Approach):**\n",
        "    *   **Prerequisites:** Install necessary libraries (`langchain`, `openai`, `python-dotenv`, the specific SQL driver like `pyodbc`, `SQLAlchemy`).\n",
        "    *   **Configuration:** Set up environment variables for Azure OpenAI (Endpoint, Key, Deployment Name) and the Database Connection String.\n",
        "    *   **Database Connection:** Establish a connection to the SQL database. SQLAlchemy is a good way to manage this, as LangChain integrates well with it. Create a `SQLDatabase` object using LangChain.\n",
        "    *   **LLM Setup:** Initialize the Azure OpenAI LLM client using LangChain's wrapper (`AzureChatOpenAI`).\n",
        "    *   **Agent/Chain Creation:** Use LangChain's SQL toolkit/agent. The `create_sql_agent` function is the standard way. It needs the LLM and the `SQLDatabase` object. This agent encapsulates the logic for:\n",
        "        *   Understanding the user's natural language question.\n",
        "        *   Inspecting the database schema (using the `SQLDatabase` object).\n",
        "        *   Generating the appropriate SQL query using the LLM.\n",
        "        *   Executing the SQL query against the database.\n",
        "        *   (Optionally) Summarizing the results using the LLM.\n",
        "    *   **Query Execution:** Call the agent's `run()` method with the natural language query.\n",
        "    *   **Integration:** Wrap this logic in a function or class that can be called from the chatbot's backend (e.g., a Flask/FastAPI endpoint).\n",
        "    *   **Testing:** Test with the specific queries mentioned in the Definition of Done.\n",
        "\n",
        "4.  **Detailed Implementation Steps & Code Structure:**\n",
        "\n",
        "    *   **Imports:** List all necessary imports (`os`, `dotenv`, `SQLAlchemy`, `langchain` components: `SQLDatabase`, `AzureChatOpenAI`, `create_sql_agent`, `AgentExecutor`, `SQLDatabaseToolkit`).\n",
        "    *   **Load Environment Variables:** Use `load_dotenv()` and `os.getenv()`. Add checks to ensure variables are present.\n",
        "    *   **Database Setup:**\n",
        "        *   Get the connection string.\n",
        "        *   Create SQLAlchemy engine: `create_engine(connection_string)`. Handle potential connection errors (though LangChain might handle some internally).\n",
        "        *   Create LangChain `SQLDatabase`: `SQLDatabase(engine=engine)`. Mention potential options like specifying included tables.\n",
        "    *   **LLM Setup:**\n",
        "        *   Instantiate `AzureChatOpenAI`, passing deployment name, endpoint, key, API version, temperature, etc.\n",
        "    *   **Agent Setup:**\n",
        "        *   Create the `SQLDatabaseToolkit`: `SQLDatabaseToolkit(db=db, llm=llm)`.\n",
        "        *   Create the agent executor: `create_sql_agent(llm=llm, toolkit=toolkit, verbose=True, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION)`. Explain `verbose=True` for debugging. Mention different agent types if relevant, but stick to the default recommended one initially.\n",
        "    *   **Query Function:** Create a function `query_database_nl(natural_language_query)` that takes the user's text and calls `agent_executor.run(natural_language_query)`. Include error handling (`try...except`).\n",
        "    *   **Chatbot Integration Point:** Explain where this function would be called (e.g., inside a Flask route handler). Show a simple example structure.\n",
        "    *   **Testing Block (`if __name__ == \\\"__main__\\\":`)**:\n",
        "        *   Define the list of test queries.\n",
        "        *   Loop through the queries, call `query_database_nl`, and print the results.\n",
        "        *   Add print statements to show the flow (Query -> Result).\n",
        "\n",
        "5.  **Refine and Review:**\n",
        "    *   **Clarity:** Is the code easy to understand? Add comments explaining key parts (agent creation, toolkit, etc.).\n",
        "    *   **Completeness:** Does it cover all parts of the Definition of Done? (Connection, Integration, Specific Queries).\n",
        "    *   **Error Handling:** Basic `try...except` is included. Mention the need for more robust handling in production.\n",
        "    *   **Security:** Briefly mention SQL injection risks and how LangChain agents *attempt* to mitigate this by generating SQL themselves rather than directly executing user input, but caution is still needed. Parameterization is generally safer if building manually, but less flexible for true NL2SQL.\n",
        "    *   **Dependencies:** Explicitly list the `pip install` commands.\n",
        "    *   **Configuration:** Emphasize storing secrets securely (`.env`, Key Vault).\n",
        "    *   **Database Schema:** Mention the importance of the database schema being accessible/understandable by the agent (LangChain's `SQLDatabase` helps here by default).\n",
        "    *   **Resource Matching:** Ensure the chosen approach aligns with the provided Python resource (the GitHub link points to a Q&A over *search* results, not direct NL2SQL, but LangChain is the standard Python tool for the *actual* NL2SQL task described). Acknowledge this potential discrepancy but explain why LangChain is the better fit for the *task description*.\n",
        "\n",
        "6.  **Final Output Generation:** Write the explanation and code, following the structured plan. Ensure the code blocks are correctly formatted. Address each point in the Definition of Done explicitly.\"\"\"),\n",
        "                types.Part.from_text(text=\"\"\"Okay, let's switch gears and implement the Natural Language to SQL (NL2SQL) capability using Python, leveraging LangChain as it's a very popular and effective framework for this in the Python ecosystem.\n",
        "\n",
        "**Assumptions:**\n",
        "\n",
        "1.  You have a SQL Server database (or another SQL database like PostgreSQL, MySQL) with tables like `Orders`, `Customers`, `OrderDetails`, `Movies` (or similar schema relevant to the queries).\n",
        "2.  You have the **ODBC Driver for SQL Server** (or the appropriate driver for your DB) installed on the machine where the Python code will run.\n",
        "3.  You have the database connection string.\n",
        "4.  You have your Azure OpenAI endpoint, API key, and the `turbogpt` deployment name.\n",
        "5.  You are working within your Python chatbot application structure (e.g., using Flask, FastAPI, or another framework).\n",
        "\n",
        "**Phase 1: Project Setup and Dependencies**\n",
        "\n",
        "1.  **Install Required Libraries:**\n",
        "    ```bash\n",
        "    pip install langchain openai python-dotenv sqlalchemy pyodbc tiktoken langchain-experimental\n",
        "    # For PostgreSQL use: pip install psycopg2-binary\n",
        "    # For MySQL use: pip install mysql-connector-python\n",
        "    ```\n",
        "    *   `langchain`: The core framework.\n",
        "    *   `openai`: The official OpenAI library (used by LangChain for Azure).\n",
        "    *   `python-dotenv`: To load environment variables.\n",
        "    *   `sqlalchemy`: A SQL toolkit and ORM, used by LangChain to interact with the DB.\n",
        "    *   `pyodbc`: The ODBC driver interface for SQL Server (replace if using a different DB).\n",
        "    *   `tiktoken`: Used by LangChain for token counting.\n",
        "    *   `langchain-experimental`: Contains the SQL agent components.\n",
        "\n",
        "2.  **Set up Environment Variables:**\n",
        "    *   Create a `.env` file in your project root:\n",
        "        ```dotenv\n",
        "        AZURE_OPENAI_API_KEY=\\\"YOUR_AZURE_OPENAI_API_KEY\\\"\n",
        "        AZURE_OPENAI_ENDPOINT=\\\"YOUR_AZURE_OPENAI_ENDPOINT\\\"\n",
        "        AZURE_OPENAI_DEPLOYMENT_NAME=\\\"turbogpt\\\" # Your GPT deployment for generating SQL\n",
        "        AZURE_OPENAI_API_VERSION=\\\"2023-07-01-preview\\\" # Or a newer compatible version\n",
        "\n",
        "        # Replace with your actual DATABASE connection string\n",
        "        # Ensure it's URL-encoded if it contains special characters\n",
        "        # Example for SQL Server with pyodbc:\n",
        "        DATABASE_URL=\\\"mssql+pyodbc://your_user:your_password@your_server/your_database?driver=ODBC+Driver+17+for+SQL+Server&Encrypt=yes&TrustServerCertificate=no&Connection+Timeout=30\\\"\n",
        "        # Example for PostgreSQL:\n",
        "        # DATABASE_URL=\\\"postgresql+psycopg2://your_user:your_password@your_host:your_port/your_database\\\"\n",
        "        # Example for MySQL:\n",
        "        # DATABASE_URL=\\\"mysql+mysqlconnector://your_user:your_password@your_host:your_port/your_database\\\"\n",
        "        ```\n",
        "    *   *Security Note:* For production, use more secure methods like Azure Key Vault to store secrets.\n",
        "\n",
        "**Phase 2: Database and LLM Integration (LangChain)**\n",
        "\n",
        "3.  **Implement NL2SQL Logic:**\n",
        "    *   Create a Python file (e.g., `nl_to_sql.py`) or integrate this logic into your chatbot's service layer.\n",
        "\n",
        "    ```python\n",
        "    import os\n",
        "    from dotenv import load_dotenv\n",
        "    from sqlalchemy import create_engine\n",
        "    from langchain.agents import create_sql_agent # Updated import\n",
        "    from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "    from langchain.sql_database import SQLDatabase\n",
        "    from langchain_openai import AzureChatOpenAI # Updated import\n",
        "    from langchain.agents import AgentExecutor\n",
        "    from langchain.agents.agent_types import AgentType # To specify agent type\n",
        "\n",
        "\n",
        "    # Load environment variables from .env file\n",
        "    load_dotenv()\n",
        "\n",
        "    # --- Database Connection ---\n",
        "    db_url = os.getenv(\\\"DATABASE_URL\\\")\n",
        "    if not db_url:\n",
        "        raise ValueError(\\\"DATABASE_URL environment variable not set.\\\")\n",
        "\n",
        "    try:\n",
        "        # Create SQLAlchemy engine\n",
        "        # Add connect_args for specific driver options if needed, e.g., for ODBC encryption\n",
        "        engine = create_engine(db_url)\n",
        "\n",
        "        # Create LangChain SQLDatabase object\n",
        "        # You can optionally include specific tables: include_tables=['Orders', 'Customers', ...]\n",
        "        # This helps the LLM focus and reduces schema complexity/tokens\n",
        "        db = SQLDatabase(engine=engine)\n",
        "        print(\\\"Successfully connected to the database.\\\")\n",
        "        print(f\\\"Dialect: {db.dialect}\\\")\n",
        "        # You can uncomment the line below to see tables Langchain detects\n",
        "        # print(f\\\"Usable Tables: {db.get_usable_table_names()}\\\")\n",
        "    except Exception as e:\n",
        "        print(f\\\"Error connecting to database or creating SQLDatabase object: {e}\\\")\n",
        "        raise\n",
        "\n",
        "    # --- Azure OpenAI LLM Setup ---\n",
        "    openai_api_key = os.getenv(\\\"AZURE_OPENAI_API_KEY\\\")\n",
        "    azure_endpoint = os.getenv(\\\"AZURE_OPENAI_ENDPOINT\\\")\n",
        "    deployment_name = os.getenv(\\\"AZURE_OPENAI_DEPLOYMENT_NAME\\\")\n",
        "    api_version = os.getenv(\\\"AZURE_OPENAI_API_VERSION\\\")\n",
        "\n",
        "    if not all([openai_api_key, azure_endpoint, deployment_name, api_version]):\n",
        "        raise ValueError(\\\"Azure OpenAI environment variables not fully set.\\\")\n",
        "\n",
        "    llm = AzureChatOpenAI(\n",
        "        openai_api_version=api_version,\n",
        "        azure_deployment=deployment_name,\n",
        "        azure_endpoint=azure_endpoint,\n",
        "        openai_api_key=openai_api_key,\n",
        "        temperature=0, # Lower temperature for more deterministic SQL generation\n",
        "        # model_version=\\\"0613\\\" # Specify model version if needed\n",
        "    )\n",
        "    print(\\\"AzureChatOpenAI client initialized.\\\")\n",
        "\n",
        "    # --- LangChain SQL Agent Setup ---\n",
        "    try:\n",
        "        # Create the SQL Database Toolkit\n",
        "        # This toolkit bundles tools for listing tables, getting schema, querying, etc.\n",
        "        toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "        print(\\\"SQLDatabaseToolkit created.\\\")\n",
        "\n",
        "        # Create the SQL Agent Executor\n",
        "        # This agent uses the LLM and the toolkit to answer questions about the database\n",
        "        agent_executor = create_sql_agent(\n",
        "            llm=llm,\n",
        "            toolkit=toolkit,\n",
        "            verbose=True,  # Set to True to see the agent's thought process/SQL queries\n",
        "            agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "            # You might experiment with agent_type=AgentType.OPENAI_FUNCTIONS for newer models\n",
        "            # prefix=\\\"You are an agent designed to interact with a SQL database...\\\", # Customize agent instructions if needed\n",
        "            # handle_parsing_errors=True # Add robust error handling\n",
        "        )\n",
        "        print(\\\"SQL Agent Executor created.\\\")\n",
        "    except Exception as e:\n",
        "        print(f\\\"Error creating LangChain SQL Agent: {e}\\\")\n",
        "        raise\n",
        "\n",
        "    # --- Function to Query Database using Natural Language ---\n",
        "    def query_database_nl(natural_language_query: str) -> str:\n",
        "        \\\"\\\"\\\"\n",
        "        Takes a natural language query and uses the LangChain SQL agent\n",
        "        to get an answer from the database.\n",
        "        \\\"\\\"\\\"\n",
        "        print(f\\\"\\\\n--- Processing NL Query: '{natural_language_query}' ---\\\")\n",
        "        try:\n",
        "            # Use agent_executor.invoke for newer Langchain versions if run is deprecated\n",
        "            # result = agent_executor.invoke({\\\"input\\\": natural_language_query}) # Newer invoke syntax\n",
        "            result = agent_executor.run(natural_language_query) # Older run syntax\n",
        "            # The result format might vary, it could be a string or a dict\n",
        "            # In newer versions, the output is often in result['output']\n",
        "            # return result.get('output', str(result)) if isinstance(result, dict) else str(result)\n",
        "            return str(result) # Keep it simple for now\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\\\"Error during agent execution: {e}\\\")\n",
        "            # You might want to return a user-friendly error message\n",
        "            return f\\\"Sorry, I encountered an error trying to answer that: {e}\\\"\n",
        "\n",
        "    # --- DONE: Made a connection to the database programmatically ---\n",
        "    # --- DONE: Integrated chatbot with deployment that can talk to the database (via query_database_nl function) ---\n",
        "\n",
        "    # --- Main Execution Block for Testing ---\n",
        "    if __name__ == \\\"__main__\\\":\n",
        "        test_queries = [\n",
        "            \\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\",\n",
        "            \\\"Fetch top 10 customers with most total orders and customer names in one table\\\",\n",
        "            \\\"Fetch top 20 most watched movies from order details and their titles in one table\\\"\n",
        "            # Add more test queries if needed\n",
        "        ]\n",
        "\n",
        "        for query in test_queries:\n",
        "            answer = query_database_nl(query)\n",
        "            print(f\\\"\\\\nNL Query: {query}\\\")\n",
        "            print(f\\\"Answer: {answer}\\\")\n",
        "            print(\\\"-\\\" * 40)\n",
        "\n",
        "    # --- DONE: Made a query to the database thru the chatbot: \\\"Fetch me 10 records from dbo.Orders table grouped by CustomerID\\\" ---\n",
        "    # --- DONE: Created queries: Fetch top 10 customers with most total orders and customer names in one table ---\n",
        "    # --- DONE: Created queries: Fetch top 20 most watched movies from order details and their titles in one table ---\n",
        "\n",
        "```\n",
        "\n",
        "**Phase 3: Chatbot Backend Integration**\n",
        "\n",
        "4.  **Call the NL2SQL Function:**\n",
        "    *   In your chatbot's backend code (e.g., in your Flask or FastAPI route handler for processing user messages), import and call the `query_database_nl` function.\n",
        "\n",
        "    *   **Example (Flask):**\n",
        "        ```python\n",
        "        from flask import Flask, request, jsonify\n",
        "        # Assume nl_to_sql.py is in the same directory or accessible via PYTHONPATH\n",
        "        from nl_to_sql import query_database_nl\n",
        "\n",
        "        app = Flask(__name__)\n",
        "\n",
        "        @app.route('/chat', methods=['POST'])\n",
        "        def chat_handler():\n",
        "            data = request.get_json()\n",
        "            user_message = data.get('message')\n",
        "\n",
        "            if not user_message:\n",
        "                return jsonify({\\\"error\\\": \\\"No message provided\\\"}), 400\n",
        "\n",
        "            # --- Simple Logic: Check if message is likely a DB query ---\n",
        "            # You might have more sophisticated intent detection here\n",
        "            is_db_query = any(kw in user_message.lower() for kw in [\\\"fetch\\\", \\\"show me\\\", \\\"list\\\", \\\"how many\\\", \\\"top customers\\\", \\\"movies\\\"])\n",
        "\n",
        "            if is_db_query:\n",
        "                # Call the NL to SQL function\n",
        "                bot_response = query_database_nl(user_message)\n",
        "            else:\n",
        "                # Handle regular chat (e.g., call your previous OpenAI chat logic)\n",
        "                # from challenge1_chatbot import ask_openai_with_data # Example\n",
        "                # bot_response = ask_openai_with_data(user_message)\n",
        "                bot_response = \\\"I can primarily answer questions about our movie database right now.\\\"\n",
        "\n",
        "\n",
        "            return jsonify({\\\"reply\\\": bot_response})\n",
        "\n",
        "        if __name__ == '__main__':\n",
        "            # Make sure to configure host and port appropriately\n",
        "            app.run(host='0.0.0.0', port=5000, debug=True) # Debug should be False in production\n",
        "        ```\n",
        "\n",
        "**Explanation:**\n",
        "\n",
        "1.  **Dependencies:** We install LangChain, SQLAlchemy (for DB abstraction), `pyodbc` (or your DB driver), `openai` SDK, `python-dotenv`, and `tiktoken`.\n",
        "2.  **Configuration:** Sensitive keys and connection strings are loaded from a `.env` file.\n",
        "3.  **Database Connection:** SQLAlchemy's `create_engine` establishes the connection pool. LangChain's `SQLDatabase` class wraps this engine, providing methods the LLM agent uses to inspect the schema (`get_table_info`) and execute queries (`run`). Specifying tables via `include_tables` is recommended for complex schemas.\n",
        "4.  **LLM Initialization:** We set up the `AzureChatOpenAI` client with the necessary Azure credentials and deployment details. A low `temperature` (like 0) is often best for SQL generation to make it more predictable.\n",
        "5.  **SQL Agent:** `SQLDatabaseToolkit` gathers the necessary tools (like query execution, schema inspection). `create_sql_agent` builds the core agent logic. It uses the LLM and the toolkit to decide which tools to use based on the natural language input. `verbose=True` is invaluable for debugging as it shows the LLM's reasoning and the exact SQL generated.\n",
        "6.  **`query_database_nl` Function:** This is the main interface. It takes the user's text query and passes it to the `agent_executor.run()` (or `.invoke()`) method. The agent handles the entire process: NL -> SQL -> Execution -> Result Formatting (often involves another LLM call to make the raw SQL result more readable).\n",
        "7.  **Chatbot Integration:** The example shows how a simple Flask route can decide whether to send a message to the NL2SQL function or handle it differently.\n",
        "8.  **Testing:** The `if __name__ == \\\"__main__\\\":` block executes the specific queries from the Definition of Done, demonstrating the functionality.\n",
        "\n",
        "**Conclusion (Python)**\n",
        "\n",
        "You've now equipped your Python chatbot with the ability to query your SQL database using natural language. By leveraging LangChain's SQL agent, Azure OpenAI, and SQLAlchemy, the chatbot can understand user requests about data, translate them into SQL queries, execute them against the database, and return the results, fulfilling all the requirements of the challenge. Remember to focus on security (SQL injection prevention, which the agent helps with but isn't foolproof) and robust error handling in a production environment.\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "        types.Content(\n",
        "            role=\"user\",\n",
        "            parts=[\n",
        "                types.Part.from_text(text=\"\"\"INSERT_INPUT_HERE\"\"\"),\n",
        "            ],\n",
        "        ),\n",
        "    ]\n",
        "    generate_content_config = types.GenerateContentConfig(\n",
        "        response_mime_type=\"text/plain\",\n",
        "    )\n",
        "\n",
        "    for chunk in client.models.generate_content_stream(\n",
        "        model=model,\n",
        "        contents=contents,\n",
        "        config=generate_content_config,\n",
        "    ):\n",
        "        print(chunk.text, end=\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}